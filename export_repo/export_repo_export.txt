<codebase_context>
  <dirtree root="/home/caleb/repo/utils/export_repo">
export_repo (3.0k/33.1k)
||-- configs (1.5k lines/20.1k tokens)
||   |-- autocrop.json (10/109)
||   |-- autocropper.json (12/172)
||   |-- bulk_dl.json (14/227)
||   |-- convnext.json (15/174)
||   |-- cosm-c360-data.json (12/184)
||   |-- cosm-c360-tools.json (12/175)
||   |-- export_repo.json (13/110)
||   |-- ezmd.json (11/123)
||   |-- ezprompt.json (11/124)
||   |-- flash-attn.json (22/309)
||   |-- h5merge-mini.json (12/146)
||   |-- h5merge.json (12/160)
||   |-- h5pull.json (11/121)
||   |-- hFormer0-serve.json (10/114)
||   |-- ibrida.json (19/372)
||   |-- ibridaDB_v0r1_export.json (13/296)
||   |-- ibridaDB_v0r1_ingest.json (10/117)
||   |-- ibridaDB_v0rX.json (12/200)
||   |-- ibrida_analysis.json (13/182)
||   |-- ibrida_autocrop.json (13/191)
||   |-- ladybird_data.json (13/148)
||   |-- linnaeus-deploymentXL.json (24/331)
||   |-- metaformer.json (11/84)
||   |-- metaformer1.json (12/100)
||   |-- metaformer2.json (11/84)
||   |-- model-explorer.json (13/120)
||   |-- nextjs.json (8/107)
||   |-- polliFormer-COPAP.json (12/147)
||   |-- polliFormer-Dyn.json (18/245)
||   |-- polliFormer-DynSlim.json (13/138)
||   |-- polliFormer-J25_0e0.json (13/212)
||   |-- polliFormer-aug.json (11/103)
||   |-- polliFormer-autobatch.json (13/165)
||   |-- polliFormer-autoresume.json (15/205)
||   |-- polliFormer-autoscale.json (20/328)
||   |-- polliFormer-blade-angio-0.json (14/279)
||   |-- polliFormer-buildData.json (12/143)
||   |-- polliFormer-classification0.json (21/297)
||   |-- polliFormer-classification1.json (21/297)
||   |-- polliFormer-codeOnly.json (11/151)
||   |-- polliFormer-configData.json (12/150)
||   |-- polliFormer-configModel.json (14/261)
||   |-- polliFormer-configModelMini.json (13/162)
||   |-- polliFormer-data.json (12/171)
||   |-- polliFormer-debugCOPAP.json (13/157)
||   |-- polliFormer-deploymentXL.json (28/443)
||   |-- polliFormer-deploymentXLw.json (56/1.0k)
||   |-- polliFormer-doxDyn.json (16/274)
||   |-- polliFormer-gradnorm.json (25/278)
||   |-- polliFormer-gradnorm2.json (27/310)
||   |-- polliFormer-gradnormSlim.json (16/192)
||   |-- polliFormer-gradnormSlim2.json (14/161)
||   |-- polliFormer-hierarchyMini.json (16/222)
||   |-- polliFormer-hierarchyXL.json (28/462)
||   |-- polliFormer-logging.json (14/172)
||   |-- polliFormer-loggingSlim.json (14/163)
||   |-- polliFormer-loss.json (26/303)
||   |-- polliFormer-loss2.json (21/201)
||   |-- polliFormer-loss3.json (18/193)
||   |-- polliFormer-mFormerV1.json (18/349)
||   |-- polliFormer-meta.json (18/279)
||   |-- polliFormer-metrics.json (14/200)
||   |-- polliFormer-models-codeOnly.json (11/112)
||   |-- polliFormer-models.json (15/311)
||   |-- polliFormer-modelsDyn.json (16/315)
||   |-- polliFormer-modelsPruned-codeOnly.json (11/119)
||   |-- polliFormer-modelsPrunedInv-codeOnly.json (11/122)
||   |-- polliFormer-modelsSlim.json (18/344)
||   |-- polliFormer-modelsSlim2.json (16/290)
||   |-- polliFormer-paramFilters.json (16/248)
||   |-- polliFormer-serve.json (10/118)
||   |-- polliFormer-tests.json (12/171)
||   |-- polliFormer-train.json (16/260)
||   |-- polliFormer-utils.json (11/105)
||   |-- polliFormer.json (13/190)
||   |-- polliOS-codeOnly.json (13/140)
||   |-- polliOS.json (13/117)
||   |-- pollinalysis-code-mini.json (18/245)
||   |-- pollinalysis-code.json (16/242)
||   |-- pollinalysis-full.json (24/362)
||   |-- pollinalysis.json (13/147)
||   |-- rope-vit.json (15/178)
||   |-- sam2-webapp.json (12/190)
||   |-- sam2.json (12/189)
||   |-- sam2_demo.json (15/280)
||   |-- squarecrop.json (13/147)
||   |-- trackers.json (12/148)
||   |-- uv_docs_raw.json (14/121)
||   |-- uv_med.json (46/365)
||   |-- uv_mini.json (69/588)
||   |-- uv_xl.json (33/288)
||   |-- vggt.json (15/174)
||   \-- wandb_sweep.json (12/124)
|\-- export_repo_to_txt.py (1.5k/12.9k)
  </dirtree>
  <files>
    <file path="export_repo_to_txt.py" line_interval="25">
# --- START OF FILE export_repo_to_txt.py ---
import json
import math
import os
import platform
import sys
import xml.sax.saxutils as saxutils  # For escaping attribute values safely

import nbformat
from nbconvert import MarkdownExporter
from nbconvert.preprocessors import ClearOutputPreprocessor

# Attempt to import rich, provide guidance if missing
try:
    from rich.console import Console
    from rich.table import Table

    console = Console()
except ImportError:
    print("Rich library not found. Tables will use basic formatting.")
    print("Please install it: pip install rich")
    console = None

# Attempt to import tiktoken, provide guidance if missing
#|LN|25|try:
    import tiktoken
except ImportError:
    print("Tiktoken library not found. Token counts will not be generated.")
    print("Please install it: pip install tiktoken")
    tiktoken = None

# Base paths for different operating systems
BASE_PATHS = {
    "Darwin": "/Users/carbon/repo",  # macOS
    "Windows": r"C:\Users\front\Documents\GitHub",
    "Linux": "/home/caleb/repo",  # Linux default
}

# Known Unix-style paths to convert
UNIX_PATHS_TO_CONVERT = [
    "/home/caleb/repo",
    "/home/caleb/Documents/GitHub/",
    "/Users/caleb/Documents/GitHub",
]


def convert_absolute_path(path: str) -> str:
    """
    Convert an absolute path from one system's format to another.
#|LN|50|    Handles known path patterns and converts them appropriately.
    """
    if not isinstance(path, str) or not os.path.isabs(path):
        return path

    # Get the appropriate base path for the current system
    target_base = get_base_path()

    # Try to convert from known Unix paths
    for unix_path in UNIX_PATHS_TO_CONVERT:
        if path.startswith(unix_path):
            relative_path = path[len(unix_path) :].lstrip("/")
            return os.path.join(target_base, relative_path)

    # If path starts with C:\Users\front\Documents\GitHub and we are on macOS/Linux, convert it
    windows_base = r"C:\Users\front\Documents\GitHub"
    if path.startswith(windows_base) and platform.system() != "Windows":
        relative_path = path[len(windows_base) :].lstrip("\\")
        return os.path.join(target_base, relative_path.replace("\\", "/"))

    # If path starts with /Users/carbon/repo and we are on Windows/Linux, convert it
    macos_base = "/Users/carbon/repo"
    if path.startswith(macos_base) and platform.system() != "Darwin":
        relative_path = path[len(macos_base) :].lstrip("/")
        return os.path.join(target_base, relative_path)
#|LN|75|
    # If path starts with /home/caleb/repo and we are on Windows/macOS, convert it
    linux_base = "/home/caleb/repo"
    if path.startswith(linux_base) and platform.system() not in [
        "Linux",
        "Pop!_OS",
    ]:  # Assuming Pop!_OS reports as Linux
        relative_path = path[len(linux_base) :].lstrip("/")
        return os.path.join(target_base, relative_path)

    # If no specific conversion matched, assume it's already in a usable format or doesn't need conversion
    return path


class PathConverter:
    @staticmethod
    def to_system_path(path: str) -> str:
        """
        Convert the given path to the current system's native format.
        On Windows, forward slashes become backslashes, etc.
        Uses os.path.normpath for robustness.
        """
        if not isinstance(path, str):
            return path

#|LN|100|        # Normalize separators first
        if platform.system() == "Windows":
            # Prioritize converting known Unix roots if they somehow slipped through
            if path.startswith("/"):
                is_likely_unix_abs = len(path) > 1 and path[1] != ":"
                if is_likely_unix_abs:
                    # Attempt conversion based on known patterns first might be needed here too
                    # For simplicity, assuming initial conversion handled most cases.
                    # Just normalize for now.
                    pass  # The normpath should handle this if it's like /c/Users/...

            normalized_path = path.replace("/", "\\")
        else:
            normalized_path = path.replace("\\", "/")

        # Use os.path.normpath to clean up separators, handle ., .. etc.
        # This can change the path semantics slightly if not careful (e.g., removing trailing slash)
        # but generally makes paths more canonical.
        try:
            # normpath can fail on invalid Windows paths like 'C:file.txt'
            final_path = os.path.normpath(normalized_path)
        except ValueError:
            # Handle cases where normpath might fail on Windows
            print(
                f"Warning: os.path.normpath failed for path: {normalized_path}. Using original."
#|LN|125|            )
            final_path = normalized_path

        return final_path

    @staticmethod
    def normalize_config_paths(config: dict) -> dict:
        """
        Normalize all relevant paths in the config to the current system's format.
        Also normalizes paths within lists. Ensures repo_root is absolute.
        """
        if "repo_root" in config and config["repo_root"]:
            # 1. Convert known absolute paths from other systems
            config["repo_root"] = convert_absolute_path(config["repo_root"])
            # 2. Convert slashes/backslashes to native format and normalize
            config["repo_root"] = PathConverter.to_system_path(config["repo_root"])
            # 3. Ensure it's absolute
            config["repo_root"] = os.path.abspath(config["repo_root"])

        path_keys = [
            "dirs_to_traverse",
            "subdirs_to_exclude",
            "files_to_exclude",
            "files_to_include",
            "additional_dirs_to_traverse",
#|LN|150|            "dirs_for_tree",
        ]
        for key in path_keys:
            if key in config and isinstance(config[key], list):
                normalized_paths = []
                for p in config[key]:
                    if isinstance(p, str) and not p.startswith(("http:", "https:")):
                        path_to_normalize = p
                        # Convert absolute paths first if possible
                        if os.path.isabs(p):
                            path_to_normalize = convert_absolute_path(p)
                        # Normalize format (slashes) and structure
                        normalized_paths.append(
                            PathConverter.to_system_path(path_to_normalize)
                        )
                    else:
                        normalized_paths.append(p)  # Keep non-strings or URLs as is
                config[key] = normalized_paths

        # Handle output_dir similarly
        if "output_dir" in config and config["output_dir"]:
            config["output_dir"] = convert_absolute_path(config["output_dir"])
            config["output_dir"] = PathConverter.to_system_path(config["output_dir"])
            # Ensure output_dir is absolute *after* potential joining later
            # We don't make it absolute here because it might be relative to repo_root
#|LN|175|
        # Ensure additional_dirs_to_traverse contains absolute paths
        if "additional_dirs_to_traverse" in config:
            abs_additional_dirs = []
            for p in config.get("additional_dirs_to_traverse", []):
                if isinstance(p, str):
                    abs_p = p
                    if not os.path.isabs(abs_p):
                        # Assume relative to repo_root if not absolute
                        print(
                            f"Warning: Path '{p}' in 'additional_dirs_to_traverse' is relative. Assuming relative to repo_root: {config.get('repo_root', 'MISSING')}"
                        )
                        if config.get("repo_root"):
                            abs_p = os.path.join(config["repo_root"], p)
                        else:
                            print(
                                f"Error: Cannot resolve relative path '{p}' because repo_root is not defined. Skipping."
                            )
                            continue

                    abs_p = convert_absolute_path(
                        abs_p
                    )  # Convert cross-system absolute
                    abs_p = PathConverter.to_system_path(abs_p)  # Normalize format
                    abs_additional_dirs.append(
#|LN|200|                        os.path.abspath(abs_p)
                    )  # Ensure absolute
            config["additional_dirs_to_traverse"] = abs_additional_dirs

        return config


class RepoExporter:
    def __init__(self, config: dict, config_filename: str = None):
        """
        Initialize the RepoExporter with the given config dictionary.
        :param config: The loaded or constructed configuration object.
        :param config_filename: Optional name of the config file used, for output labeling.
        """
        config = PathConverter.normalize_config_paths(
            config
        )  # Apply normalization early

        self.repo_root = config["repo_root"]
        self.export_name = config["export_name"]
        self.dirs_to_traverse = config.get("dirs_to_traverse", [])
        self.include_top_level_files = config.get("include_top_level_files", "none")
        self.included_extensions = config.get("included_extensions", [])
        self.subdirs_to_exclude = config.get("subdirs_to_exclude", [])
        self.files_to_exclude = config.get("files_to_exclude", [])
#|LN|225|        self.depth = config.get("depth", -1)
        self.dump_config = config.get("dump_config", False)
        self.exhaustive_dir_tree = config.get("exhaustive_dir_tree", False)
        self.files_to_include = config.get("files_to_include", [])
        self.additional_dirs_to_traverse = config.get("additional_dirs_to_traverse", [])
        self.always_exclude_patterns = config.get(
            "always_exclude_patterns", ["export.txt"]
        )
        self.dirs_for_tree = config.get("dirs_for_tree", [])

        # New config options for line numbering
        self.line_number_interval = config.get("line_number_interval", 25)  # Default 25
        self.line_number_min_length = config.get("line_number_min_length", 150)
        default_annotate_extensions = list(
            dict.fromkeys(
                [  # Ensure unique extensions
                    ".py",
                    ".js",
                    ".ts",
                    ".tsx",
                    ".java",
                    ".cpp",
                    ".c",
                    ".go",
                    ".rs",
#|LN|250|                    ".sh",
                    ".sql",
                ]
            )
        )
        raw_annotate_extensions = config.get(
            "annotate_extensions", default_annotate_extensions
        )
        # Normalize extensions to be lowercase and start with a dot
        self.annotate_extensions = [
            ext.lower() if ext.startswith(".") else f".{ext.lower()}"
            for ext in raw_annotate_extensions
        ]
        self.line_number_prefix = config.get("line_number_prefix", "|LN|")

        # Map of file extensions to their single-line comment tokens
        self.comment_tokens_map = {
            ".py": "#",
            ".sh": "#",
            ".rb": "#",
            ".pl": "#",
            ".yaml": "#",
            ".yml": "#",
            ".dockerfile": "#",
            ".r": "#",
#|LN|275|            ".ps1": "#",
            ".js": "//",
            ".ts": "//",
            ".tsx": "//",
            ".java": "//",
            ".c": "//",
            ".cpp": "//",
            ".h": "//",
            ".hpp": "//",
            ".cs": "//",
            ".go": "//",
            ".rs": "//",
            ".kt": "//",
            ".kts": "//",
            ".scala": "//",
            ".swift": "//",
            ".php": "//",
            ".sql": "--",
            ".lua": "--",
            ".hs": "--",
            ".ada": "--",
            # Add more as needed. HTML/XML/CSS use block comments, Markdown <!-- -->.
        }

        # Hardcoded blacklists
#|LN|300|        self.blacklisted_dirs = [
            "__pycache__",
            ".git",
            ".venv",
            ".vscode",
            "node_modules",
            "build",
            "dist",
        ]
        self.blacklisted_files = [
            "uv.lock",
            "LICENSE",
            ".DS_Store",
            "*.pyc",
            "*.swp",
            "*.swo",
        ]  # Added common ignores

        # Runtime attributes
        self.config_filename = config_filename
        self.output_dir = config.get("output_dir", None)
        if self.output_dir:
            # Ensure output_dir is absolute. If it wasn't absolute in config, assume relative to CWD.
            if not os.path.isabs(self.output_dir):
                self.output_dir = os.path.abspath(
#|LN|325|                    os.path.join(os.getcwd(), self.output_dir)
                )
            else:
                self.output_dir = os.path.abspath(
                    self.output_dir
                )  # Handles normalization if already absolute

        self.output_file = self.get_output_file_path()

        # Add output file itself to exclusion patterns dynamically
        output_filename = os.path.basename(self.output_file)
        if output_filename not in self.always_exclude_patterns:
            self.always_exclude_patterns.append(output_filename)

        # Tiktoken Initializer
        self.tokenizer = None
        if tiktoken:
            try:
                self.tokenizer = tiktoken.get_encoding("o200k_base")
            except Exception as e:
                print(
                    f"Warning: Failed to initialize tiktoken tokenizer 'o200k_base'. Token counts unavailable. Error: {e}"
                )
                self.tokenizer = None

#|LN|350|        # --- Content Buffering & Stats ---
        # Store tuples: (display_path, absolute_path, annotated_content, is_ipynb_converted, line_interval_used)
        self.buffered_files = []
        self.exported_files_count = {}
        self.total_lines = 0
        self.total_tokens = 0
        self.line_counts_by_file = {}  # Uses display_path as key
        self.token_counts_by_file = {}  # Uses display_path as key
        self.line_counts_by_dir = {}  # Uses display_path segments as keys
        self.token_counts_by_dir = {}  # Uses display_path segments as keys
        # NEW: Dictionary to store aggregate stats per extension
        # Structure: { ".py": {"files": 0, "lines": 0, "tokens": 0}, ... }
        self.stats_by_extension = {}

    def get_output_file_path(self) -> str:
        """
        Return the absolute path for the export file, handling relative/absolute export_name
        and optional output_dir.
        """
        # Normalize export_name path separators first
        path = PathConverter.to_system_path(self.export_name)

        if os.path.isabs(path):
            print(
                f"Warning: 'export_name' ({self.export_name}) is absolute. Ignoring 'output_dir' if set."
#|LN|375|            )
            output_path = os.path.abspath(
                path
            )  # Ensure it's truly absolute and normalized
        elif self.output_dir:
            if not os.path.exists(self.output_dir):
                print(f"Creating output directory: {self.output_dir}")
                try:
                    os.makedirs(self.output_dir, exist_ok=True)
                except OSError as e:
                    raise ValueError(
                        f"Failed to create output directory '{self.output_dir}': {e}"
                    )
            output_path = os.path.abspath(os.path.join(self.output_dir, path))
        else:
            if not self.repo_root or not os.path.isdir(self.repo_root):
                raise ValueError(
                    f"Repo root '{self.repo_root}' is invalid or not specified, and no 'output_dir' was provided for relative export_name."
                )
            output_path = os.path.abspath(os.path.join(self.repo_root, path))

        # Ensure the directory for the output file exists
        output_file_dir = os.path.dirname(output_path)
        if not os.path.exists(output_file_dir):
            print(f"Creating directory for output file: {output_file_dir}")
#|LN|400|            try:
                os.makedirs(output_file_dir, exist_ok=True)
            except OSError as e:
                raise ValueError(
                    f"Failed to create directory for output file '{output_path}': {e}"
                )

        return output_path

    def convert_ipynb_to_md(self, notebook_content: str) -> str:
        """
        Convert an IPython notebook JSON string to Markdown, clearing outputs.
        """
        try:
            notebook = nbformat.reads(notebook_content, as_version=4)
            clear_output = ClearOutputPreprocessor()
            processed_notebook, _ = clear_output.preprocess(notebook, {})
            markdown_exporter = MarkdownExporter()
            markdown_content, _ = markdown_exporter.from_notebook_node(
                processed_notebook
            )
            return markdown_content
        except Exception as e:
            print(f"Error converting ipynb: {e}")
            return f"<!-- Error converting notebook: {e} -->\n{notebook_content}"
#|LN|425|
    def buffer_file_content(self, absolute_path: str):
        """
        Reads, processes (ipynb), calculates stats, and stores file content in memory buffer.
        Updates line/token counts and statistics.
        Determines the display path (relative or absolute).
        """
        if not os.path.isfile(absolute_path):
            print(
                f"Warning: Skipping non-file path provided to buffer_file_content: {absolute_path}"
            )
            return

        # Determine display path (relative if under repo_root, else absolute normalized)
        display_path = absolute_path
        try:
            # Use normpath to handle potential differences in how paths are constructed (e.g. //)
            norm_repo_root = os.path.normpath(self.repo_root)
            norm_abs_path = os.path.normpath(absolute_path)

            # Check prefix using normalized paths
            if norm_abs_path.startswith(norm_repo_root + os.sep):
                display_path = os.path.relpath(norm_abs_path, norm_repo_root)
            # Ensure display_path uses consistent separators
            display_path = PathConverter.to_system_path(display_path)
#|LN|450|        except ValueError as e:
            # Handle potential errors if paths are malformed (e.g., on Windows with mixed separators)
            print(
                f"Warning: Could not determine relative path for {absolute_path} against {self.repo_root}. Using absolute path. Error: {e}"
            )
            display_path = PathConverter.to_system_path(absolute_path)

        if self.should_exclude_file(absolute_path, display_path):
            return

        file_extension = os.path.splitext(absolute_path)[
            1
        ].lower()  # Use lower for case-insensitivity
        # Normalize included extensions if it's a list
        normalized_included_extensions = self.included_extensions
        if isinstance(normalized_included_extensions, list):
            normalized_included_extensions = [
                ext.lower() for ext in normalized_included_extensions
            ]

        if (
            normalized_included_extensions != "all"
            and file_extension not in normalized_included_extensions
        ):
            return
#|LN|475|
        try:
            with open(absolute_path, "r", encoding="utf-8", errors="ignore") as f:
                content_for_stats = f.read()  # This is the original content for stats

            is_ipynb_converted = False
            if file_extension == ".ipynb":
                content_for_stats = self.convert_ipynb_to_md(content_for_stats)
                is_ipynb_converted = True

            if any(bf[1] == absolute_path for bf in self.buffered_files):
                return  # Already processed

            # --- Calculate stats on original (or .ipynb converted) content BEFORE annotation ---
            line_count = content_for_stats.count("\n") + 1
            token_count = 0
            if self.tokenizer:
                try:
                    token_count = len(self.tokenizer.encode(content_for_stats))
                except Exception as e:
                    print(
                        f"Warning: Tiktoken failed to encode content for {display_path}. Error: {e}"
                    )

            # --- Annotate content for output (stats are already captured from original) ---
#|LN|500|            # Use original file_extension for determining annotation rules, even if converted from ipynb
            annotated_content, line_interval_used = (
                self._annotate_content_with_line_numbers(
                    content_for_stats, file_extension
                )
            )

            # Update Overall and Per-Extension Stats (using original counts)
            ext_key = file_extension or "._no_extension_"
            if ext_key not in self.stats_by_extension:
                self.stats_by_extension[ext_key] = {"files": 0, "lines": 0, "tokens": 0}
            self.stats_by_extension[ext_key]["files"] += 1
            self.stats_by_extension[ext_key]["lines"] += line_count
            self.stats_by_extension[ext_key]["tokens"] += token_count

            self.total_lines += line_count
            self.total_tokens += token_count
            self.line_counts_by_file[display_path] = line_count
            self.token_counts_by_file[display_path] = token_count

            # Store file info with *annotated* content for final output generation
            self.buffered_files.append(
                (
                    display_path,
                    absolute_path,
#|LN|525|                    annotated_content,
                    is_ipynb_converted,
                    line_interval_used,
                )
            )

        except Exception as e:
            print(f"Error reading or processing file {absolute_path}: {e}")

    def should_exclude_file(self, absolute_path: str, display_path: str) -> bool:
        """Check if a file should be excluded based on various rules."""
        filename = os.path.basename(absolute_path)

        # 1. Hardcoded blacklist (basename)
        if filename in self.blacklisted_files:
            return True

        # 2. Always exclude patterns (basename or suffix matching)
        if any(
            filename == pattern or filename.endswith(pattern.lstrip("*"))
            for pattern in self.always_exclude_patterns
        ):
            return True

        # 3. files_to_exclude (match against display_path)
#|LN|550|        # This checks if the display_path *ends with* one of the exclusion paths.
        # Normalize separators for comparison.
        norm_display_path = PathConverter.to_system_path(display_path)
        if any(
            norm_display_path == PathConverter.to_system_path(exclude)
            or norm_display_path.endswith(
                os.sep + PathConverter.to_system_path(exclude)
            )
            for exclude in self.files_to_exclude
        ):
            return True

        return False

    def should_exclude_dir(self, absolute_dir_path: str) -> bool:
        """Check if a directory should be excluded during traversal."""
        dir_name = os.path.basename(absolute_dir_path)

        if dir_name in self.blacklisted_dirs:
            return True

        # subdirs_to_exclude check (relative path prefix match *if* under repo_root)
        try:
            norm_repo_root = os.path.normpath(self.repo_root)
            norm_abs_dir_path = os.path.normpath(absolute_dir_path)
#|LN|575|
            if norm_abs_dir_path.startswith(norm_repo_root + os.sep):
                relative_path = os.path.relpath(norm_abs_dir_path, norm_repo_root)
                relative_path = PathConverter.to_system_path(
                    relative_path
                )  # Normalize for comparison

                for exclude in self.subdirs_to_exclude:
                    norm_exclude = PathConverter.to_system_path(exclude.rstrip(os.sep))
                    # Check exact match or if it's a parent directory
                    if relative_path == norm_exclude or relative_path.startswith(
                        norm_exclude + os.sep
                    ):
                        return True
        except ValueError as e:
            print(
                f"Warning: Error calculating relative path for exclusion check: {absolute_dir_path} vs {self.repo_root}. Error: {e}"
            )
            # Decide behavior: exclude or include? Let's be conservative and not exclude if unsure.
            return False

        return False

    def traverse_directory(self, relative_start_dir: str):
        """Walk through a directory *relative* to repo_root, buffering eligible files."""
#|LN|600|        # Ensure relative_start_dir uses native separators for join
        relative_start_dir_norm = PathConverter.to_system_path(relative_start_dir)
        abs_start_dir = os.path.abspath(
            os.path.join(self.repo_root, relative_start_dir_norm)
        )

        if not os.path.isdir(abs_start_dir):
            print(
                f"Warning: Directory '{relative_start_dir}' ({abs_start_dir}) does not exist relative to repo root. Skipping."
            )
            return

        print(f"Traversing internal dir: {relative_start_dir}")
        initial_depth = abs_start_dir.count(os.sep)

        for root, dirs, files in os.walk(abs_start_dir, topdown=True):
            current_abs_depth = root.count(os.sep)
            relative_depth = current_abs_depth - initial_depth

            # Depth limiting (relative to start of traversal)
            if self.depth != -1 and relative_depth >= self.depth:
                dirs[:] = []  # Don't recurse further in this branch
                continue  # Skip files at this depth too

            # Directory exclusion
#|LN|625|            original_dirs = list(dirs)  # Copy before modifying dirs[:]
            dirs[:] = [
                d
                for d in original_dirs
                if not self.should_exclude_dir(os.path.join(root, d))
            ]

            # Buffer eligible files
            for file in files:
                abs_file_path = os.path.join(root, file)
                self.buffer_file_content(abs_file_path)

    def traverse_external_directory(self, abs_start_dir: str):
        """Walk through an *absolute* external directory path, buffering eligible files."""
        abs_start_dir = os.path.abspath(PathConverter.to_system_path(abs_start_dir))

        if not os.path.isdir(abs_start_dir):
            print(
                f"Warning: External directory '{abs_start_dir}' does not exist or is not a directory. Skipping."
            )
            return

        print(f"Traversing external dir: {abs_start_dir}")
        initial_depth = abs_start_dir.count(os.sep)

#|LN|650|        for root, dirs, files in os.walk(abs_start_dir, topdown=True):
            current_abs_depth = root.count(os.sep)
            relative_depth = current_abs_depth - initial_depth

            # Depth limiting
            if self.depth != -1 and relative_depth >= self.depth:
                dirs[:] = []
                continue

            # Directory exclusion (using same logic, checks basename and relative-to-repo if applicable)
            original_dirs = list(dirs)
            dirs[:] = [
                d
                for d in original_dirs
                if not self.should_exclude_dir(os.path.join(root, d))
            ]

            # Buffer eligible files
            for file in files:
                abs_file_path = os.path.join(root, file)
                self.buffer_file_content(
                    abs_file_path
                )  # This handles display path correctly

    def include_specific_files(self):
#|LN|675|        """Process the `files_to_include` list, buffering eligible files."""
        if not self.files_to_include:
            return

        print("Processing specific files to include...")
        for file_path_config in self.files_to_include:
            # Normalize path from config first
            normalized_file_path = PathConverter.to_system_path(file_path_config)

            if os.path.isabs(normalized_file_path):
                abs_path = os.path.abspath(
                    normalized_file_path
                )  # Ensure canonical absolute path
                if os.path.isfile(abs_path):
                    self.buffer_file_content(abs_path)
                else:
                    print(
                        f"Warning: Specified absolute file to include not found or not a file: {abs_path}"
                    )
            else:
                # Assume relative path is relative to repo_root
                abs_path = os.path.abspath(
                    os.path.join(self.repo_root, normalized_file_path)
                )
                if os.path.isfile(abs_path):
#|LN|700|                    self.buffer_file_content(abs_path)
                else:
                    print(
                        f"Warning: Specified relative file to include not found relative to repo root: {normalized_file_path} (resolved to {abs_path})"
                    )

    def should_include_in_tree(self, abs_dir_path: str) -> bool:
        """Determine if a directory should appear in the directory tree output."""
        if not abs_dir_path.startswith(self.repo_root):
            return False  # Only show dirs within repo_root in the tree

        dir_name = os.path.basename(abs_dir_path)

        if dir_name.startswith(
            "."
        ):  # Exclude hidden dirs unless explicitly included elsewhere?
            # Let's allow hidden dirs if they contain included files or are part of traversal/tree lists
            # Need to refine this check
            pass  # Revisit simple hidden dir exclusion later if needed

        if dir_name in self.blacklisted_dirs:
            return False

        # Apply subdirs_to_exclude filter unless exhaustive
        if not self.exhaustive_dir_tree:
#|LN|725|            if self.should_exclude_dir(abs_dir_path):
                return False

        # Check against dirs_for_tree if specified
        if self.dirs_for_tree:
            try:
                relative_path = os.path.relpath(abs_dir_path, self.repo_root)
                relative_path_norm = PathConverter.to_system_path(relative_path)

                # Check if this dir is exactly listed OR is a child of a listed dir
                is_explicitly_or_implicitly_in_tree = False
                for tree_dir in self.dirs_for_tree:
                    norm_tree_dir = PathConverter.to_system_path(tree_dir)
                    if (
                        relative_path_norm == norm_tree_dir
                        or relative_path_norm.startswith(norm_tree_dir + os.sep)
                    ):
                        is_explicitly_or_implicitly_in_tree = True
                        break
                if (
                    not is_explicitly_or_implicitly_in_tree and relative_path != "."
                ):  # Allow root implicitly
                    return False
            except ValueError:
                return False  # Cannot determine relative path
#|LN|750|
        # Final check: Does this directory contain any exported files OR non-empty subdirs?
        try:
            rel_dir_path = os.path.relpath(abs_dir_path, self.repo_root)
            rel_dir_path_norm = PathConverter.to_system_path(rel_dir_path)
            if rel_dir_path_norm == ".":
                rel_dir_path_norm = ""  # Root representation

            # Check files directly within this directory
            has_direct_exported_files = any(
                os.path.dirname(PathConverter.to_system_path(display_path))
                == rel_dir_path_norm
                for display_path in self.line_counts_by_file.keys()
                if not os.path.isabs(display_path)
            )
            if has_direct_exported_files:
                return True  # Include if it has direct files

            # Check aggregated stats for the directory (includes content from subdirs)
            _, token_count = self.get_stats_for_path(
                rel_dir_path_norm
            )  # Use helper to get aggregated counts
            if token_count > 0:  # Check token count as primary indicator of content
                return True

#|LN|775|            # If no direct files and no aggregated content, exclude
            return False

        except ValueError:
            return False  # Error getting relative path

    def compute_directory_stats(self):
        """
        Compute aggregated line and token counts for directories based on buffered files.
        Uses display_path keys.
        """
        self.line_counts_by_dir = {}
        self.token_counts_by_dir = {}

        # Iterate through files with counts
        for display_path, lines in self.line_counts_by_file.items():
            tokens = self.token_counts_by_file.get(display_path, 0)

            # Only aggregate for relative paths within the repo root
            if os.path.isabs(display_path):
                continue

            parts = display_path.split(os.sep)
            # Aggregate counts up the directory chain (to parent dirs)
            for i in range(1, len(parts)):  # Stop before the filename itself
#|LN|800|                dir_path_key = os.sep.join(parts[:i])
                self.line_counts_by_dir[dir_path_key] = (
                    self.line_counts_by_dir.get(dir_path_key, 0) + lines
                )
                self.token_counts_by_dir[dir_path_key] = (
                    self.token_counts_by_dir.get(dir_path_key, 0) + tokens
                )

        # Add root counts (sum of all relative files) - handles files directly in root
        root_lines = sum(
            l for dp, l in self.line_counts_by_file.items() if not os.path.isabs(dp)
        )
        root_tokens = sum(
            t for dp, t in self.token_counts_by_file.items() if not os.path.isabs(dp)
        )
        self.line_counts_by_dir[""] = (
            root_lines  # Use empty string for root aggregate? Or '.'? Let's use ''
        )
        self.token_counts_by_dir[""] = root_tokens

    def get_stats_for_path(self, display_path: str) -> tuple[int, int]:
        """
        Return the (line_count, token_count) for a file (from _by_file)
        or directory (from _by_dir) using its display_path relative to repo_root.
        """
#|LN|825|        # Prioritize file stats if path exists in file dicts
        if display_path in self.line_counts_by_file:
            return (
                self.line_counts_by_file.get(display_path, 0),
                self.token_counts_by_file.get(display_path, 0),
            )

        # Otherwise, return directory stats (use '' for root dir)
        dir_key = display_path if display_path != "." else ""
        return (
            self.line_counts_by_dir.get(dir_key, 0),
            self.token_counts_by_dir.get(dir_key, 0),
        )

    def _format_count(self, count: int) -> str:
        """Formats counts >= 1000 with 'k' suffix, rounded to one decimal."""
        if count >= 1000:
            return f"{math.floor(count / 100) / 10:.1f}k"
        else:
            return str(count)

    def _get_comment_token_for_extension(self, ext: str) -> str | None:
        """Returns the single-line comment token for a given file extension (case-insensitive)."""
        return self.comment_tokens_map.get(ext.lower())

#|LN|850|    def _annotate_content_with_line_numbers(
        self, content: str, file_extension: str
    ) -> tuple[str, int]:
        """
        Annotates content with sparse line numbers if applicable.
        Returns the annotated content and the interval used (0 if not annotated).
        Line/token counts for stats should be calculated on the *original* content.
        """
        ext_lower = file_extension.lower()  # Ensure consistent matching

        # Check if annotation is enabled globally and for this specific extension
        if not self.line_number_interval or self.line_number_interval <= 0:
            return content, 0
        if ext_lower not in self.annotate_extensions:
            return content, 0

        comment_token = self._get_comment_token_for_extension(ext_lower)
        if not comment_token:  # No comment style defined for this extension
            return content, 0

        lines = content.splitlines()
        if len(lines) < self.line_number_min_length:
            return content, 0  # File too short to annotate

        interval = self.line_number_interval
#|LN|875|        # Construct the core part of the marker, e.g., "#|LN|"
        marker_prefix_core = f"{comment_token}{self.line_number_prefix}"

        annotated_lines = []
        for i, line_content in enumerate(lines):
            current_line_number = i + 1  # Line numbers are 1-indexed
            if current_line_number % interval == 0:
                # Prepend marker to the line: e.g., "#|LN|25|def my_func():"
                annotated_lines.append(
                    f"{marker_prefix_core}{current_line_number}|{line_content}"
                )
            else:
                annotated_lines.append(line_content)

        return "\n".join(annotated_lines), interval

    def get_directory_tree(
        self,
        abs_directory: str,
        prefix: str = "",
        current_depth: int = 0,
        stats_units_printed: bool = False,
    ):
        """
        Generate the ASCII directory tree string, showing only included items
#|LN|900|        with line and token counts.
        Operates on paths relative to repo_root for display.
        """
        if self.depth != -1 and current_depth > self.depth:
            # Only add (...) if there might have been more content deeper
            # This is hard to know for sure without listing one level deeper
            # Let's omit the (...) for simplicity unless we actually truncated visible items
            return "", stats_units_printed

        tree_str = ""
        try:
            items = sorted(os.listdir(abs_directory))
        except FileNotFoundError:
            return "", stats_units_printed  # Directory doesn't exist

        visible_items = []
        for item in items:
            item_abs_path = os.path.join(abs_directory, item)
            if os.path.isdir(item_abs_path):
                if self.should_include_in_tree(item_abs_path):
                    visible_items.append(item)
            elif os.path.isfile(item_abs_path):
                try:
                    item_display_path = os.path.relpath(item_abs_path, self.repo_root)
                    item_display_path_norm = PathConverter.to_system_path(
#|LN|925|                        item_display_path
                    )
                    # Check if the file was actually buffered (i.e., passed filters and included)
                    if item_display_path_norm in self.line_counts_by_file:
                        visible_items.append(item)
                except ValueError:
                    # Cannot make relative path (e.g., different drive on Windows)
                    # Only include if it was buffered (which implies it was included some other way)
                    if any(bf[1] == item_abs_path for bf in self.buffered_files):
                        # How to represent this in the tree? Maybe skip external files in tree?
                        # For now, let's only add items relative to repo_root.
                        pass

        for i, item in enumerate(visible_items):
            item_abs_path = os.path.join(abs_directory, item)
            try:
                item_rel_path = os.path.relpath(item_abs_path, self.repo_root)
                item_rel_path_norm = PathConverter.to_system_path(item_rel_path)
            except ValueError:
                continue  # Skip if cannot make relative (shouldn't happen if already filtered)

            line_count, token_count = self.get_stats_for_path(item_rel_path_norm)

            connector = "|-- " if i < len(visible_items) - 1 else "\\-- "

#|LN|950|            # Format stats string
            stats_str = ""
            # Check if item has content OR is a directory (even if empty)
            is_dir = os.path.isdir(item_abs_path)
            if line_count > 0 or token_count > 0 or is_dir:
                line_str = self._format_count(line_count)
                token_str = self._format_count(token_count)
                if not stats_units_printed and (line_count > 0 or token_count > 0):
                    stats_str = f" ({line_str} lines/{token_str} tokens)"
                    stats_units_printed = True  # Set flag after first use
                else:
                    stats_str = f" ({line_str}/{token_str})"

            tree_str += f"{prefix}{connector}{item}{stats_str}\n"

            if is_dir:
                sub_prefix = prefix + ("|   " if i < len(visible_items) - 1 else "    ")
                # Recurse, passing the current state of stats_units_printed
                subtree_str, stats_units_printed = self.get_directory_tree(
                    item_abs_path, sub_prefix, current_depth + 1, stats_units_printed
                )
                tree_str += subtree_str

        # If depth limit was hit AND we omitted visible items, add indicator
        # This check is tricky. Let's skip the indicator for now.
#|LN|975|
        return tree_str, stats_units_printed

    def _build_files_string_recursive(
        self, path_prefix: str, files_in_dir: list, indent_level: int
    ) -> str:
        """
        Helper to recursively build the <files> section string with nested <dir> and <file> tags.
        Embeds raw file content.
        """
        indent = "  " * indent_level
        parts = []

        # Separate files and directories at the current level
        current_level_files = {}  # display_path -> (abs_path, content, is_ipynb, line_interval_used)
        subdirs = {}  # subdir_key (relative path) -> list of file tuples

        # Normalize prefix for comparison
        norm_prefix = PathConverter.to_system_path(path_prefix)
        prefix_len = len(norm_prefix) if norm_prefix else -1

        for file_tuple in files_in_dir:
            display_path, abs_path, content, is_ipynb, line_interval_used = file_tuple
            # Ensure display_path uses system separators for splitting logic
            norm_display_path = PathConverter.to_system_path(display_path)
#|LN|1000|
            # Determine path relative to the current prefix
            relative_to_prefix = (
                norm_display_path[prefix_len + 1 :]
                if prefix_len >= -1
                else norm_display_path
            )

            if os.sep in relative_to_prefix:
                # Subdirectory file
                subdir_name = relative_to_prefix.split(os.sep)[0]
                # Construct key using the *original* (potentially non-normalized) prefix + separator + subdir_name
                # This preserves the intended structure from display_path
                subdir_key = (
                    os.path.join(path_prefix, subdir_name)
                    if path_prefix
                    else subdir_name
                )
                if subdir_key not in subdirs:
                    subdirs[subdir_key] = []
                subdirs[subdir_key].append(file_tuple)
            else:
                # File in current directory
                current_level_files[display_path] = (
                    abs_path,
#|LN|1025|                    content,
                    is_ipynb,
                    line_interval_used,
                )

        # Add files at the current level
        for display_path, file_data_tuple in sorted(current_level_files.items()):
            abs_path, content, is_ipynb, line_interval_used = file_data_tuple
            # Escape path attribute value ONLY
            escaped_path_attr = saxutils.quoteattr(display_path)
            ipynb_attr = ' converted_from_ipynb="true"' if is_ipynb else ""
            line_interval_attr = (
                f' line_interval="{line_interval_used}"'
                if line_interval_used > 0
                else ""
            )
            parts.append(
                f"{indent}<file path={escaped_path_attr}{ipynb_attr}{line_interval_attr}>"
            )
            # --- Embed raw content directly ---
            parts.append(content)
            # ---                            ---
            parts.append(f"{indent}</file>")

        # Recurse into subdirectories
#|LN|1050|        for subdir_key, files_list in sorted(subdirs.items()):
            # Escape subdir path attribute value ONLY
            escaped_subdir_path_attr = saxutils.quoteattr(subdir_key)
            parts.append(f"{indent}<dir path={escaped_subdir_path_attr}>")
            # Recursively build content for this subdir
            parts.append(
                self._build_files_string_recursive(
                    subdir_key, files_list, indent_level + 1
                )
            )
            parts.append(f"{indent}</dir>")

        return "\n".join(parts)

    def export_repo(self):
        """
        Main export routine: Gathers files, computes stats, generates output string.
        """
        print(f"Starting export for repo: {self.repo_root}")

        # 1. Process top-level files if requested
        if self.include_top_level_files != "none":
            print("Processing top-level files...")
            try:
                items = os.listdir(self.repo_root)
#|LN|1075|                for item in items:
                    abs_item_path = os.path.join(self.repo_root, item)
                    if os.path.isfile(abs_item_path):
                        is_included_top_level = (
                            self.include_top_level_files == "all"
                            or (
                                isinstance(self.include_top_level_files, list)
                                and item in self.include_top_level_files
                            )
                        )
                        if is_included_top_level:
                            self.buffer_file_content(abs_item_path)
            except FileNotFoundError:
                print(f"Error: Repo root directory not found: {self.repo_root}")
                return
            except Exception as e:
                print(f"Error processing top-level files: {e}")

        # 2. Traverse internal directories
        if self.dirs_to_traverse:
            for rel_dir in self.dirs_to_traverse:
                self.traverse_directory(rel_dir)

        # 3. Traverse additional external directories
        if self.additional_dirs_to_traverse:
#|LN|1100|            for abs_dir in self.additional_dirs_to_traverse:
                self.traverse_external_directory(abs_dir)

        # 4. Include specific files
        self.include_specific_files()

        # --- Post-Gathering Steps ---
        print("File gathering complete. Computing stats and generating output...")

        # 5. Compute aggregated directory stats
        self.compute_directory_stats()

        # --- Build Output String Manually ---
        output_parts = []
        output_parts.append("<codebase_context>")

        # Config (Optional) - Still dump as JSON string inside tag
        if self.dump_config:
            config_tag_label = (
                self.config_filename if self.config_filename else "dynamic-config"
            )
            escaped_label = saxutils.escape(
                config_tag_label
            )  # Escape label just in case
            output_parts.append(f'  <config source="{escaped_label}">')
#|LN|1125|            try:
                config_data = {
                    k: v
                    for k, v in self.__dict__.items()
                    if not k.startswith("_")
                    and k not in ["buffered_files", "tokenizer"]
                }  # Exclude non-serializable
                # Convert Path objects to strings for JSON serialization
                serializable_config = {}
                for k, v in config_data.items():
                    if isinstance(v, Path):
                        serializable_config[k] = str(v)
                    else:
                        serializable_config[k] = v
                config_json = json.dumps(serializable_config, indent=2)
                # Escape JSON content for XML text node (optional but safer)
                output_parts.append(saxutils.escape(config_json))
            except Exception as e:
                output_parts.append(f"<!-- Error serializing config: {e} -->")
            output_parts.append("  </config>")

        # Directory Tree
        print("Generating directory tree...")
        escaped_repo_root_attr = saxutils.quoteattr(self.repo_root)
        output_parts.append(f"  <dirtree root={escaped_repo_root_attr}>")
#|LN|1150|        directory_tree_str, _ = self.get_directory_tree(
            self.repo_root, prefix="|", stats_units_printed=False
        )  # Start prefix with '|'
        # Add repo root node itself with total stats
        root_lines, root_tokens = self.get_stats_for_path(
            ""
        )  # Get aggregated root stats
        root_line_str = self._format_count(root_lines)
        root_token_str = self._format_count(root_tokens)
        # Determine if units were printed in the subtree
        # Hacky way: check if "lines" appears in the generated tree string
        units_already_printed = " lines/" in directory_tree_str
        if not units_already_printed and (root_lines > 0 or root_tokens > 0):
            root_stats_str = f" ({root_line_str} lines/{root_token_str} tokens)"
        else:
            root_stats_str = f" ({root_line_str}/{root_token_str})"

        output_parts.append(
            f"{os.path.basename(self.repo_root) or self.repo_root}{root_stats_str}"
        )  # Show root stats
        output_parts.append(
            directory_tree_str.rstrip()
        )  # Add the rest of the tree, remove trailing newline
        output_parts.append("  </dirtree>")

#|LN|1175|        # Files (Nested Structure)
        print("Generating files section...")
        output_parts.append("  <files>")

        # Separate files by origin
        repo_files = []
        external_files = []
        norm_repo_root = os.path.normpath(self.repo_root)
        for bf in self.buffered_files:
            display_path, abs_path, content, is_ipynb, line_interval_used = bf
            norm_abs_path = os.path.normpath(abs_path)
            # Check if the file's directory is the repo root or a subdirectory of it
            if norm_abs_path.startswith(norm_repo_root):
                repo_files.append(bf)
            else:
                external_files.append(bf)

        # Add repo files nested structure
        output_parts.append(
            self._build_files_string_recursive("", sorted(repo_files), indent_level=2)
        )

        # Add external files (under a separate tag)
        if external_files:
            output_parts.append("    <external_files>")
#|LN|1200|            # Sort external files by their absolute path for consistent ordering
            sorted_external = sorted(external_files, key=lambda x: x[1])
            for (
                display_path,
                abs_path,
                content,
                is_ipynb,
                line_interval_used,
            ) in sorted_external:
                escaped_path_attr = saxutils.quoteattr(
                    display_path
                )  # display_path is absolute here
                ipynb_attr = ' converted_from_ipynb="true"' if is_ipynb else ""
                line_interval_attr = (
                    f' line_interval="{line_interval_used}"'
                    if line_interval_used > 0
                    else ""
                )
                output_parts.append(
                    f"      <file path={escaped_path_attr}{ipynb_attr}{line_interval_attr}>"
                )
                output_parts.append(content)
                output_parts.append("      </file>")
            output_parts.append("    </external_files>")

#|LN|1225|        output_parts.append("  </files>")
        output_parts.append("</codebase_context>")

        # --- Write Output ---
        final_output_string = "\n".join(output_parts)
        try:
            with open(self.output_file, "w", encoding="utf-8") as f:
                f.write(final_output_string)
            print(f"\nExported to: {self.output_file}")
        except Exception as e:
            print(f"\nError writing output file {self.output_file}: {e}")

        # --- Final Summary ---
        print(f"\nExported to: {self.output_file}")
        print(f"Total number of lines exported: {self.total_lines}")
        if self.tokenizer:
            print(
                f"Total number of tokens exported (estimated, o200k_base): {self.total_tokens} ({self._format_count(self.total_tokens)})"
            )

        print("\nExported content summary by extension:")
        if self.stats_by_extension:
            if console:  # If Rich is available, use Rich table
                table = Table(show_header=True, header_style="bold")
                table.add_column("Extension", style="cyan")
#|LN|1250|                table.add_column("Files", justify="right")
                table.add_column("Lines", justify="right")
                table.add_column("Tokens", justify="right")

                sorted_extensions = sorted(self.stats_by_extension.items())
                for ext, stats in sorted_extensions:
                    table.add_row(
                        ext,
                        str(stats["files"]),
                        self._format_count(stats["lines"]),
                        self._format_count(stats["tokens"]),
                    )
                console.print(table)
            else:  # Fall back to basic formatting
                # Determine max width for alignment
                max_ext_len = (
                    max(len(ext) for ext in self.stats_by_extension.keys())
                    if self.stats_by_extension
                    else 0
                )
                max_files_len = (
                    max(len(str(s["files"])) for s in self.stats_by_extension.values())
                    if self.stats_by_extension
                    else 0
                )
#|LN|1275|                max_lines_len = (
                    max(
                        len(self._format_count(s["lines"]))
                        for s in self.stats_by_extension.values()
                    )
                    if self.stats_by_extension
                    else 0
                )
                max_tokens_len = (
                    max(
                        len(self._format_count(s["tokens"]))
                        for s in self.stats_by_extension.values()
                    )
                    if self.stats_by_extension
                    else 0
                )

                header = f"  {'Extension'.ljust(max_ext_len)}  {'Files'.rjust(max_files_len)}  {'Lines'.rjust(max_lines_len)}  {'Tokens'.rjust(max_tokens_len)}"
                print(header)
                print(
                    f"  {'-' * max_ext_len}  {'-' * max(5, max_files_len)}  {'-' * max(5, max_lines_len)}  {'-' * max(6, max_tokens_len)}"
                )

                sorted_extensions = sorted(self.stats_by_extension.items())
                for ext, stats in sorted_extensions:
#|LN|1300|                    files_str = str(stats["files"]).rjust(max_files_len)
                    lines_str = self._format_count(stats["lines"]).rjust(max_lines_len)
                    tokens_str = self._format_count(stats["tokens"]).rjust(
                        max_tokens_len
                    )
                    print(
                        f"  {ext.ljust(max_ext_len)}  {files_str}  {lines_str}  {tokens_str}"
                    )
        else:
            print("  (No files exported)")


# --- Helper Functions ---


def get_base_path() -> str:
    """Determine the base path for resolving relative repo_root paths."""
    system = platform.system()
    if "--pop" in sys.argv:
        # Specific Pop!_OS path structure if flag is present
        return PathConverter.to_system_path("/home/caleb/Documents/GitHub/")
    elif system == "Darwin":
        return PathConverter.to_system_path(BASE_PATHS["Darwin"])
    elif system == "Windows":
        return PathConverter.to_system_path(BASE_PATHS["Windows"])
#|LN|1325|    else:  # Linux default
        return PathConverter.to_system_path(BASE_PATHS["Linux"])


def load_config(config_filename: str) -> dict:
    """Load configuration from a JSON file."""
    # Append .json if not present
    if not config_filename.lower().endswith(".json"):
        config_filename_json = config_filename + ".json"
    else:
        config_filename_json = config_filename

    potential_paths = []

    # 1. Relative to script's dir/configs
    try:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        potential_paths.append(
            os.path.join(script_dir, "configs", config_filename_json)
        )
    except NameError:  # __file__ might not be defined (e.g. interactive)
        script_dir = os.getcwd()
        potential_paths.append(
            os.path.join(script_dir, "configs", config_filename_json)
        )
#|LN|1350|
    # 2. Relative to base_path/utils/export_repo/configs structure
    base_path = get_base_path()
    # Adjust base path if it points directly to the repo folder structure expected
    utils_parent_dir = base_path  # Default assumption
    if base_path.endswith("GitHub") or base_path.endswith("repo"):
        utils_parent_dir = os.path.dirname(
            base_path
        )  # Go up one level if base is GitHub or repo

    potential_paths.append(
        os.path.join(
            utils_parent_dir, "utils", "export_repo", "configs", config_filename_json
        )
    )

    # 3. Relative to current working directory
    potential_paths.append(os.path.join(os.getcwd(), config_filename_json))

    # 4. The original filename (maybe it was absolute or correctly relative already)
    potential_paths.append(config_filename)

    # Try loading from potential paths
    config_to_load = None
    loaded_path = None
#|LN|1375|    for p in potential_paths:
        p_normalized = PathConverter.to_system_path(p)
        # print(f"Debug: Trying config path: {p_normalized}") # Debugging line
        if os.path.exists(p_normalized):
            config_to_load = p_normalized
            loaded_path = p  # Store the path from which it was loaded
            break

    if not config_to_load:
        checked_paths_str = "\n - ".join(potential_paths)
        raise FileNotFoundError(
            f"Config file '{config_filename}' not found. Checked:\n - {checked_paths_str}"
        )

    try:
        print(f"Loading config from: {config_to_load}")
        with open(config_to_load, "r", encoding="utf-8") as config_file:
            config = json.load(config_file)
        # Store the actual path loaded from, relative to CWD if possible
        try:
            config["_loaded_from_path"] = os.path.relpath(loaded_path)
        except ValueError:
            config["_loaded_from_path"] = (
                loaded_path  # Keep absolute if on different drive
            )
#|LN|1400|        return config
    except json.JSONDecodeError as e:
        print(f"Error decoding JSON from {config_to_load}: {e}")
        raise
    except Exception as e:
        print(f"Error loading config {config_to_load}: {e}")
        raise


def get_default_config(repo_root_path: str) -> dict:
    """Provide a default config for direct repository path usage."""
    repo_root_path = PathConverter.to_system_path(os.path.abspath(repo_root_path))
    repo_name = (
        os.path.basename(repo_root_path) or "repo"
    )  # Handle case where path ends in separator
    default_export_name = f"{repo_name}_export.txt"
    return {
        "repo_root": repo_root_path,
        "export_name": default_export_name,
        "dirs_to_traverse": ["."],  # Traverse all from root by default
        "include_top_level_files": "all",  # Include top-level files by default when traversing '.'
        "included_extensions": "all",
        "subdirs_to_exclude": [],  # Start minimal
        "files_to_exclude": [],
        "depth": 10,
#|LN|1425|        "exhaustive_dir_tree": False,
        "files_to_include": [],
        "additional_dirs_to_traverse": [],
        "always_exclude_patterns": [
            default_export_name,
            ".DS_Store",
            "*.pyc",
            "*.swp",
            "*.swo",
            "node_modules/",
            "build/",
            "dist/",
            ".venv/",
            ".git/",
            "__pycache__/",
            ".pytest_cache/",
            ".mypy_cache/",
            ".coverage",
        ],
        "dump_config": False,
        "dirs_for_tree": [],  # Default to showing all non-excluded dirs in tree
        "output_dir": None,  # Default to outputting in repo_root
        "line_number_interval": 25,  # Default 25
        "line_number_min_length": 150,
        "annotate_extensions": [
#|LN|1450|            ".py",
            ".js",
            ".ts",
            ".tsx",
            ".java",
            ".cpp",
            ".c",
            ".go",
            ".rs",
            ".sh",
            ".sql",
        ],
        "line_number_prefix": "|LN|",
    }


# Need Path from pathlib for type hinting in RepoExporter if needed
from pathlib import Path


def main():
    args = sys.argv[1:]
    config_arg = None
    pop_flag = "--pop" in args  # Handled in get_base_path
    dump_config_flag = "--dump-config" in args
#|LN|1475|
    # Filter out flags to find the main argument
    non_flag_args = [arg for arg in args if not arg.startswith("--")]

    if len(non_flag_args) != 1:
        print(
            "Usage: python export_repo_to_txt.py [--pop] [--dump-config] <config_filename | repo_root_path>"
        )
        sys.exit(1)

    config_arg = non_flag_args[0]

    config = {}
    config_filename_label = None

    # Detect if arg is a directory or a config file name
    potential_path = PathConverter.to_system_path(config_arg)
    # Check if it's a directory *first*
    if os.path.isdir(potential_path):
        print(f"Argument '{config_arg}' is a directory. Using default config.")
        config = get_default_config(potential_path)
        config_filename_label = f"default_for_{os.path.basename(potential_path)}"
    else:
        # Assume it's a config file name
        try:
#|LN|1500|            config = load_config(config_arg)
            # Use the original arg as label unless loaded path is very different?
            config_filename_label = config.get("_loaded_from_path", config_arg)
        except FileNotFoundError as e:
            print(f"Error: {e}")
            # Fallback: Maybe it's a directory path that *looks* like a filename? Check again.
            # This case is less likely if isdir failed before, but handles edge cases.
            if os.path.isdir(potential_path):
                print(
                    f"Argument '{config_arg}' resolved to a directory after failed config load. Using default config."
                )
                config = get_default_config(potential_path)
                config_filename_label = (
                    f"default_for_{os.path.basename(potential_path)}"
                )
            else:
                print(
                    f"Argument '{config_arg}' is not a valid directory or loadable config file."
                )
                sys.exit(1)
        except Exception as e:
            print(f"Error loading or parsing config: {e}")
            import traceback

            traceback.print_exc()
#|LN|1525|            sys.exit(1)

    # Override dump_config from command line flag
    if dump_config_flag:
        config["dump_config"] = True

    try:
        exporter = RepoExporter(config, config_filename=config_filename_label)
        exporter.export_repo()
    except ValueError as e:
        print(f"Configuration or Execution Error: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
# --- END OF FILE export_repo_to_txt.py ---
    </file>
    <dir path="nfigs">
      <dir path="nfigs/s">
        <file path="configs/autocrop.json">
{
    "repo_root": "/home/caleb/repo/ibrida/ibrida/s3/postprocess/autocrop",
    "export_name": "autocrop_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["utils", "configs", "models"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".yaml", ".md"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/autocropper.json">
{
    "repo_root": "/home/caleb/repo/autocropper/src/autocropper",
    "export_name": "autocropper_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["utils", "evaluation", "models", "/home/caleb/repo/ibrida/deprecated/ibridaV1/s3/postprocess/autocrop"],
    "files_to_include": ["/home/caleb/repo/autocropper/pyproject.toml", "/home/caleb/repo/autocropper/README.md"],
    "files_to_exclude": [],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".md"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/bulk_dl.json">
{
  "repo_root": "/home/caleb/repo/ibrida/ibrida",
  "export_name": "ibrida_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["s3/download", "s3/download/utils"],
  "files_to_include": ["s3_bulk_dl_v6.py", "b2.py", "config.py", "file.py", "graceful_shutdown.py", "init.py", 
  "monitoring.py", "processing.py", "internet_connectivity_checker.py", "csv_schema.py", "paths.py", "chunk_postprocessor.py"],
  "include_top_level_files": "all",
  "included_extensions": [".py", ".yaml", ".properties", ".sh", ".xml"],
  "subdirs_to_exclude": ["pkgs", "test", "fo_dataset", "utils"],
  "files_to_exclude": ["convert_multitask_dataset_to_mmlab2.py"],
  "always_exclude_patterns": ["export.txt", "other_pattern.txt"],
  "exhaustive_dir_tree": false
}
        </file>
        <file path="configs/convnext.json">
{
  "repo_root": "/home/caleb/repo/ConvNeXt",
  "export_name": "convnext_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["models"],
  "include_top_level_files": "all",
  "included_extensions": [".py", ".md", ".txt"],
  "subdirs_to_exclude": ["__pycache__", ".git", ".venv", ".vscode"],
  "files_to_exclude": [],
  "always_exclude_patterns": ["*.pyc", "*.pyo", "*.pyd", "*.so", "*.dylib", "*.dll", "*.log", "*.swp", "*.swo", "*.DS_Store"],
  "depth": -1,
  "exhaustive_dir_tree": true,
  "dump_config": false
}

        </file>
        <file path="configs/cosm-c360-data.json">
{
    "repo_root": "/home/caleb/repo/cosm-c360-tools",
    "export_name": "cosm-c360-data_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["/datasets/dataZoo/clients/ladybird/batch_0/raw/"],
    "files_to_include": ["/datasets/dataZoo/clients/ladybird/batch_0/raw/LADYBIRD.xml", "/datasets/dataZoo/clients/ladybird/batch_0/raw/0H/0M/0S/meta.json"],
    "files_to_exclude": ["ts_to_mp4.py", "TODO.md"],
    "include_top_level_files": "none",
    "included_extensions": [".py", ".md", ".toml"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/cosm-c360-tools.json">
{
    "repo_root": "/home/caleb/repo/cosm-c360-tools",
    "export_name": "cosm-c360-tools_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["src", "docs", "tests"],
    "files_to_include": ["/home/caleb/repo/cosm-c360-tools/tests/test_data/ladybird/LADYBIRD.xml", "/home/caleb/repo/cosm-c360-tools/tests/test_data/ladybird/0H/0M/0S/meta.json"],
    "files_to_exclude": ["TODO.md"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".md", ".toml"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/export_repo.json">
{
    "repo_root": "/home/caleb/repo/utils/export_repo",
    "export_name": "export_repo_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["configs"],
    "include_top_level_files": "all",
    "files_to_include": [
    "/home/caleb/repo/utils/README.md"
    ],
    "included_extensions": [".py", ".json"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/ezmd.json">
{
    "repo_root": "/home/caleb/repo/ezmd",
    "export_name": "ezmd_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["ezmd"],
    "subdirs_to_exclude": ["dev"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".env", ".toml", ".md"],
    "always_exclude_patterns": ["uv.lock", "export.txt", ".log", ".venv", ".gitignore"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/ezprompt.json">
{
    "repo_root": "/home/caleb/repo/ezprompt",
    "export_name": "ezprompt_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["ezprompt"],
    "subdirs_to_exclude": [".dev"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".env", ".toml", ".md"],
    "always_exclude_patterns": ["uv.lock", "export.txt", ".log", ".venv", ".gitignore"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/flash-attn.json">
{
  "repo_root": "/home/caleb/repo/flash-attention/",
  "export_name": "flash-attn_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["flash_attn/modules", "flash_attn/layers"],
  "include_top_level_files": "none",
  "included_extensions": [".py", ".md", ".txt"],
  "subdirs_to_exclude": ["__pycache__", ".git", ".venv", ".vscode"],
  "files_to_exclude": [],
  "files_to_include": ["/home/caleb/repo/flash-attention/README.md",
    "/home/caleb/repo/flash-attention/usage.md",
    "/home/caleb/repo/flash-attention/flash_attn/flash_attn_interface.py",
    "/home/caleb/repo/flash-attention/flash_attn/models/vit.py",
    "flash_attn/utils/distributed.py",
    "/home/caleb/repo/flash-attention/tests/test_rotary.py",
    "/home/caleb/repo/flash-attention/tests/layers/test_rotary.py"],
  "always_exclude_patterns": ["*.pyc", "*.pyo", "*.pyd", "*.so", "*.dylib", "*.dll", "*.log", "*.swp", "*.swo", "*.DS_Store"],
  "depth": -1,
  "exhaustive_dir_tree": true,
  "dump_config": false
}

        </file>
        <file path="configs/h5merge-mini.json">
{
    "repo_root": "/home/caleb/repo/ibrida/ibrida/hdf5/merge",
    "export_name": "hdf5_merge_mini_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": [],
    "files_to_include": [],
    "files_to_exclude": ["cli.py", "h5_utils.py","config.py","input_diagnostics.py", "output_diagnostics.py", "manual_verify.py", "split_adjustment.tmp.md"],
    "include_top_level_files": "all",
    "included_extensions": [".py"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/h5merge.json">
{
    "repo_root": "/home/caleb/repo/ibrida/ibrida/hdf5/merge",
    "export_name": "hdf5_merge_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["validation"],
    "files_to_include": ["/home/caleb/repo/ibrida/ibrida/hdf5/merge_tmp/h5dump_first_train.txt", "/home/caleb/stausee-report.txt"],
    "files_to_exclude": ["manual_verify.py", "split_adjustment.tmp.md"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".md"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/h5pull.json">
{
    "repo_root": "/home/caleb/repo/ibrida/ibrida/hdf5",
    "export_name": "h5pull_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": [],
    "files_to_include": ["configs/angio_v0_pop.yaml", "configs/fixer/split0_1.yaml"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".yaml"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/hFormer0-serve.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/torchserve/hFormer0",
    "export_name": "polliFormer_serve_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["."],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".yaml", ".properties", ".sh", ".xml", ".txt"],
    "subdirs_to_exclude": ["pkgs", "test"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/ibrida.json">
{
    "repo_root": "/home/caleb/repo/ibrida/src/ibrida",
    "export_name": "ibrida_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["generator", "types", "utils"],
    "files_to_include": ["/home/caleb/repo/ibrida/pyproject.toml", "/home/caleb/repo/ibrida/README.md",
    "/home/caleb/repo/ibrida/extra/generator/configs/prod/amphibia_v0r1_full_hybrid_384.json",
    "/home/caleb/repo/ibrida/extra/generator/configs/prod/amphibia_v0r1_mini_hybrid_384.json",
    "/home/caleb/repo/ibrida/extra/generator/configs/prod/angiospermae_v0r1_full_hybrid_384.json",
    "/home/caleb/repo/ibrida/extra/generator/configs/prod/aves_v0r1_full_hybrid_384.json",
    "/home/caleb/repo/ibrida/extra/generator/configs/prod/mammalia_v0r1_full_hybrid_384.json",
    "/home/caleb/repo/ibrida/extra/generator/configs/prod/reptilia_v0r1_full_hybrid_384.json"],
    "files_to_exclude": [],
    "include_top_level_files": ["pyproject.toml", "README.md"],
    "included_extensions": [".py", ".json", ".sh"],
    "always_exclude_patterns": ["export.txt"],
    "additional_dirs_to_traverse": ["/home/caleb/repo/ibrida/extra/generator/configs"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/ibridaDB_v0r1_export.json">
{
    "repo_root": "/home/caleb/repo/ibridaDB/dbTools/export/v0",
    "export_name": "ibridaDB_v0r1_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["common", "/home/caleb/repo/ibridaDB/docs"],
    "files_to_include": ["/home/caleb/repo/ibridaDB/docker/Dockerfile", "/home/caleb/repo/ibridaDB/docker/stausee/docker-compose.yml",
    "r1/wrapper_amphibia_all_exc_nonrg_sp_inc_oor_fas_elev.sh", "r1/wrapper_angiospermae_all_exc_nonrg_sp_inc_oor_fas_elev.sh", "r1/wrapper_aves_all_exc_nonrg_sp_inc_oor_fas_elev.sh", "r1/wrapper_mammalia_all_exc_nonrg_sp.sh"],
    "files_to_exclude": ["wrapper_angiospermae_all_exc_nonrg_sp.sh", "wrapper_aves_all_exc_nonrg_sp.sh", "wrapper_mammalia_all_exc_nonrg_sp_inc_oor_fas_elev.sh"],
    "include_top_level_files": "all",
    "included_extensions": [".sh", ".sql", ".md"],
    "always_exclude_patterns": ["export.txt", ".log", "wrapper_*"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/ibridaDB_v0r1_ingest.json">
{
    "repo_root": "/home/caleb/repo/ibridaDB/dbTools/ingest/v0",
    "export_name": "ibridaDB_v0r1_ingest.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["common", "r1", "utils"],
    "include_top_level_files": "all",
    "included_extensions": [".sh", ".sql"],
    "always_exclude_patterns": ["export.txt", ".log", "wrapper_*"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/ibridaDB_v0rX.json">
{
    "repo_root": "/home/caleb/repo/ibridaDB/dbTools",
    "export_name": "ibridaDB_v0rX_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["ingest/v0", "export/v0"],
    "files_to_include": ["/home/caleb/repo/ibridaDB/docker/stausee/docker-compose.yml", "/home/caleb/repo/ibridaDB/docker/stausee/entrypoint.sh",
    "/home/caleb/repo/ibridaDB/dbTools/README.md", "/home/caleb/repo/ibridaDB/dbTools/FLOW.md", "/home/caleb/repo/ibridaDB/dbTools/schema.md"],
    "include_top_level_files": "all",
    "included_extensions": [".sh", ".md", ".sql"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/ibrida_analysis.json">
{
    "repo_root": "/home/caleb/repo/ibrida/src/ibrida",
    "export_name": "ibrida_analysis_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["generator", "types", "analysis"],
    "files_to_include": ["/home/caleb/repo/ibrida/pyproject.toml", "/home/caleb/repo/ibrida/README.md",
    "/home/caleb/repo/ibrida/extra/generator/configs/prod/pta_non_rg_v0r1_hybrid.json"],
    "files_to_exclude": [],
    "include_top_level_files": ["pyproject.toml", "README.md"],
    "included_extensions": [".py", ".ipynb"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/ibrida_autocrop.json">
{
    "repo_root": "/home/caleb/repo/ibrida/src/ibrida",
    "export_name": "ibrida_autocrop_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["generator", "types", "/home/caleb/repo/ibrida/deprecated/ibridaV1/s3/postprocess/autocrop"],
    "files_to_include": ["/home/caleb/repo/ibrida/pyproject.toml", "/home/caleb/repo/ibrida/README.md",
    "/home/caleb/repo/ibrida/extra/autocrop/mmdet_context.txt"],
    "files_to_exclude": [],
    "include_top_level_files": ["pyproject.toml", "README.md"],
    "included_extensions": [".py"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/ladybird_data.json">
{
    "repo_root": "/home/caleb/ladybird_failed_copy",
    "export_name": "ladybird_data_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["0H"],
    "subdirs_to_exclude": [],
    "include_top_level_files": "all",
    "included_extensions": [".json", ".xml"],
    "files_to_include": ["/home/caleb/ladybird_failed_copy/LADYBIRD.xml"],
    "files_to_exclude": [],
    "always_exclude_patterns": ["export.txt", ".egg-info", "__pycache__", ".DS_Store", ":Zone.Identifier"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/linnaeus-deploymentXL.json">
{
    "repo_root": "/home/caleb/repo/linnaeus",
    "export_name": "linnaeus_deploymentXL_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["linnaeus"],
    "include_top_level_files": ["README.md", "pyproject.toml", ".gitignore"],
    "included_extensions": [".py", ".md", ".txt", ".yaml", ".sh"],
    "files_to_include": [
    "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_reptilia_mFormerV1_sm_run4.yaml",
    "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_mini_mFormerV1_sm_run3_test_Apr21b_noGC.yaml",
    "/home/caleb/repo/linnaeus/tools/docker/Dockerfile",
    "/home/caleb/repo/linnaeus/linnaeus/requirements.txt",
    "/home/caleb/repo/polliFormer/work/active/assets/datasets/dataset_sizes.json"
    ],
    "additional_dirs_to_traverse": [
      "/home/caleb/repo/linnaeus/docs",
      "/home/caleb/repo/linnaeus/configs/model/archs",
      "/home/caleb/repo/linnaeus/tools"
    ],
    "files_to_exclude": ["console_ui.py"],
    "subdirs_to_exclude": ["utils/inference"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/metaformer.json">
{
  "repo_root": "/home/caleb/repo/Polli-Brain/metaformer",
  "export_name": "metaformer_repo_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["models"],
  "include_top_level_files": "all",
  "included_extensions": [".py", ".yaml", ".md"],
  "exhaustive_dir_tree": false
}


        </file>
        <file path="configs/metaformer1.json">
{
  "repo_root": "/home/caleb/repo/Polli-Brain/metaformer",
  "export_name": "metaformer_repo_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["models"],
  "include_top_level_files": "all",
  "included_extensions": [".py", ".yaml", ".md"],
  "exhaustive_dir_tree": false,
  "files_to_include": ["experiment_log.md", "base2.yaml"]
}


        </file>
        <file path="configs/metaformer2.json">
{
  "repo_root": "/home/caleb/repo/Polli-Brain/metaformer",
  "export_name": "metaformer_repo_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["models", "data"],
  "include_top_level_files": "all",
  "included_extensions": [".py", ".yaml"],
  "exhaustive_dir_tree": false
}


        </file>
        <file path="configs/model-explorer.json">
{
    "repo_root": "/home/caleb/repo/Polli-Brain/model-explorer",
    "export_name": "model-explorer-repo-export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["example_colabs", "src", "model-explorer.wiki"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".yaml", ".md"],
    "exhaustive_dir_tree": false,
    "subdirs_to_exclude": ["server"],
    "depth": 10
  }
  
  
        </file>
        <file path="configs/nextjs.json">
{
    "repo_root": "/home/caleb/repo/polli-labs-mantine/",
    "export_name": "polli_labs_nextjs_repo_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["components", "content", "pages", "public", "theme", "types"],
    "include_top_level_files": ["package.json", "tsconfig.json"],
    "included_extensions": [".ts", ".js", ".tsx", ".jsx", ".json"]
  }
        </file>
        <file path="configs/polliFormer-COPAP.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer_copap_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["h5data", "aug"],
    "include_top_level_files": "none",
    "included_extensions": [".py", ".yaml"],
    "files_to_include": ["main.py", "config.py", "docs/data/copap.md"],
    "files_to_exclude": ["main_v0.py", "main_v1.py", "completed_plans.md"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/polliFormer-Dyn.json">
{
  "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
  "export_name": "polliFormer_Dyn_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["loss","ops_schedule", "utils/logging", "utils/metrics"],
  "include_top_level_files": "all",
  "included_extensions": [".py"],
  "files_to_include": ["/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_hybrid_ft_sm_19.yaml",
    "style_guide/metrics.md", "style_guide/schedule_parameters.md",
  "utils/schedule_utils.py", 
"/home/caleb/repo/polliFormer/docs/training/metrics.md",
"/home/caleb/repo/polliFormer/docs/training/scheduling.md",
"/home/caleb/repo/polliFormer/docs/evaluation/validation.md"],
  "files_to_exclude": ["console_ui.py", "backblaze.py"],
  "subdirs_to_exclude": ["utils/inference"],
  "always_exclude_patterns": ["export.txt"],
  "exhaustive_dir_tree": true
}
        </file>
        <file path="configs/polliFormer-DynSlim.json">
{
  "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
  "export_name": "polliFormer_DynSlim_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["components"],
  "include_top_level_files": "none",
  "included_extensions": [".py"],
  "files_to_include": ["lr_scheduler.py", "optimizer.py"],
  "files_to_exclude": ["console_ui.py", "backblaze.py"],
  "subdirs_to_exclude": ["utils/inference"],
  "always_exclude_patterns": ["export.txt"],
  "exhaustive_dir_tree": true
}
        </file>
        <file path="configs/polliFormer-J25_0e0.json">
{
    "repo_root": "/home/caleb/repo/polliFormer",
    "export_name": "polliFormer_buildData_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["polliFormer/h5data"],
    "dirs_for_tree": ["polliFormer", "configs/experiments"],
    "include_top_level_files": ["config.py", "main.py"],
    "included_extensions": [".py", ".yaml"],
    "files_to_include": ["polliFormer/utils/wandb.py", "polliFormer/utils/config_utils.py", "polliFormer/docs/data/copap.md", "configs/models/mFormer/mFormerV0_0_heteroHA_TS.yaml",
"configs/archs/mFormerV0/mFormerV0_0.yaml", "configs/archs/mFormerV0/mFormerV0.yaml"],
    "always_exclude_patterns": ["export.txt", "224.yaml", ".bak.py"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/polliFormer-aug.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer-aug_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["aug"],
    "include_top_level_files": "none",
    "included_extensions": [".py"],
    "files_to_exclude": ["export.py"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/polliFormer-autobatch.json">
{
  "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
  "export_name": "polliFormer_autobatch_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["utils"],
  "include_top_level_files": "all",
  "included_extensions": [".py"],
  "files_to_include": ["utils/wandb.py", "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_hybrid.yaml"],
  "files_to_exclude": ["dataset_processor.py", "console_ui.py", "backblaze.py"],
  "subdirs_to_exclude": ["utils/inference"],
  "always_exclude_patterns": ["export.txt"],
  "exhaustive_dir_tree": true
}
        </file>
        <file path="configs/polliFormer-autoresume.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer-autoresume_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": [],
    "dirs_to_exclude": [],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".yaml"],
    "files_to_exclude": ["export.py", "console_ui.py"],
    "files_to_include": ["utils/autobatch.py", "utils/wandb.py", "utils/checkpoint.py", "utils/model_utils.py", "utils/config_utils.py",
    "utils/distributed.py", "utils/metrics/tracker.py", "utils/backblaze.py",
        "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_hybrid_ft_sm.yaml"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/polliFormer-autoscale.json">
{
  "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
  "export_name": "polliFormer_autoscale_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["loss","components", "ops_schedule", "utils/logging", "utils/metrics"],
  "include_top_level_files": "all",
  "included_extensions": [".py"],
  "files_to_include": [ "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_hybrid_ft_sm_14.yaml",
  "/home/caleb/repo/polliFormer/polliFormer/h5data/grouped_batch_sampler.py",
  "/home/caleb/repo/polliFormer/polliFormer/h5data/h5_dataloader.py",
    "/home/caleb/repo/polliFormer/polliFormer/utils/schedule_utils.py",
"utils/param_filters.py", "utils/distributed.py", "utils/checkpoint.py",
  "/home/caleb/repo/polliFormer/style_guide/metrics.md", "/home/caleb/repo/polliFormer/style_guide/model_metadata.md",
    "/home/caleb/repo/polliFormer/style_guide/schedule_parameters.md",
    "/home/caleb/repo/polliFormer/work/active/schedule_reform_PRD.md"],
  "files_to_exclude": ["console_ui.py", "backblaze.py"],
  "subdirs_to_exclude": ["utils/inference"],
  "always_exclude_patterns": ["export.txt"],
  "exhaustive_dir_tree": true
}
        </file>
        <file path="configs/polliFormer-blade-angio-0.json">
{
    "repo_root": "/home/caleb/repo/polliFormer",
    "export_name": "polliFormer_blade_angio_0_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": [],
    "include_top_level_files": "none",
    "included_extensions": [".py", ".yaml", ".md"],
    "files_to_include": ["/home/caleb/repo/polliFormer/configs/experiments/tests/blade_angio_0.yaml", "/home/caleb/repo/polliFormer/configs/models/mFormer/mFormerV0_0_heteroHA_TS.yaml",
    "/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_0.yaml", "/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0.yaml",
"/home/caleb/repo/polliFormer/configs/models/mFormer/mFormerV0_0_heteroHA_TS.yaml", "/home/caleb/repo/polliFormer/configs/model/components/classification_heads/L1020304050_linear.yaml"],
    "files_to_exclude": [],
    "always_exclude_patterns": ["export.txt", ".egg-info", "__pycache__", ".DS_Store"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/polliFormer-buildData.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer_buildData_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["h5data"],
    "dirs_for_tree": ["polliFormer", "configs/experiments"],
    "include_top_level_files": ["config.py", "main.py"],
    "files_to_exclude": ["h5data/dataset_processor.py"],
    "included_extensions": [".py", ".yaml"],
    "always_exclude_patterns": ["export.txt", "224.yaml", ".bak.py"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/polliFormer-classification0.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer_classification0_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["loss", "models/heads"],
    "include_top_level_files": "all",
    "included_extensions": [".py"],
    "files_to_include": [
        "utils/param_filters.py",
        "h5data/build.py",
        "h5data/vectorized_dataset_processor.py",
        "h5data/prefetching_hybrid_dataset.py",
    "models/mFormerV0.py", "models/build.py", "models/model_factory.py", "models/base_model.py",
    "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_mini_0_conditional.yaml",
    "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_mini_0_hsoftmax.yaml",
    "/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_sm.yaml"],
    "files_to_exclude": ["console_ui.py", "backblaze.py", "optimizer.py", "config.py"],
    "subdirs_to_exclude": ["utils/inference"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/polliFormer-classification1.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer_classification1_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["loss", "models/heads"],
    "include_top_level_files": "all",
    "included_extensions": [".py"],
    "files_to_include": [
        "h5data/build.py",
        "h5data/vectorized_dataset_processor.py",
        "h5data/prefetching_hybrid_dataset.py",
        "utils/dataset_metadata.py",
    "models/mFormerV0.py", "models/build.py", "models/model_factory.py", "models/base_model.py",
    "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_mini_0_conditional.yaml",
    "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_mini_0_hsoftmax.yaml",
    "/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_sm.yaml"],
    "files_to_exclude": ["console_ui.py", "backblaze.py", "optimizer.py", "config.py"],
    "subdirs_to_exclude": ["utils/inference"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/polliFormer-codeOnly.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer_codeOnly_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["aug", "h5data", "configs", "models", "loss", "utils", "components", "ibrida", "evaluation", "serving"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".yaml"],
    "files_to_exclude": ["main_v0.py", "main_v1.py", "completed_plans.md"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/polliFormer-configData.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer_configData_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["h5data", "ibrida", "loss", "utils"],
    "dirs_for_tree": ["polliFormer", "configs/experiments"],
    "include_top_level_files": ["config.py", "main.py"],
    "included_extensions": [".py"],
    "files_to_include": ["polliFormer/docs/data/copap.md"],
    "always_exclude_patterns": ["export.txt", "224.yaml", ".bak.py"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/polliFormer-configModel.json">
{
    "repo_root": "/home/caleb/repo/polliFormer",
    "export_name": "polliFormer_configModel_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["polliFormer", "configs"],
    "subdirs_to_exclude": ["polliFormer/tests", "polliFormer/serving", "polliFormer/evaluation", "polliFormer/aug",
        "polliFormer/h5data", "polliFormer/logs", "polliFormer/loss"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".yaml", ".md"],
    "files_to_include": ["/home/caleb/repo/polliFormer/polliFormer/h5data/h5dump_first_train.txt", "/home/caleb/repo/polliFormer/.vscode/launch.json"],
    "files_to_exclude": ["README.md", "TODO.md", "training.md", "mFormerV1.py", "mFormerV1.md", "training.md", "mFormerV1.py"],
    "always_exclude_patterns": ["export.txt", ".egg-info", "__pycache__", ".DS_Store"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/polliFormer-configModelMini.json">
{
    "repo_root": "/home/caleb/repo/polliFormer",
    "export_name": "polliFormer_configModelMini_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["configs"],
    "subdirs_to_exclude": [],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".yaml"],
    "files_to_include": ["/home/caleb/repo/polliFormer/polliFormer/config.py", "/home/caleb/repo/polliFormer/polliFormer/utils/config_utils.py"],
    "files_to_exclude": [],
    "always_exclude_patterns": ["export.txt", ".egg-info", "__pycache__", ".DS_Store"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/polliFormer-data.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer_data_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["h5data", "aug"],
    "files_to_include": ["utils/config_utils.py", "main.py", "config.py", "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_hybrid.yaml"],
    "files_to_exclude": ["dataset_processor.py", "console_ui.py", "backblaze.py"],
    "include_top_level_files": "none",
    "included_extensions": [".py"],
    "always_exclude_patterns": ["export.txt", "224.yaml", ".bak.py"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/polliFormer-debugCOPAP.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer_debugCOPAP_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["h5data"],
    "include_top_level_files": "none",
    "included_extensions": [".py"],
    "files_to_include": ["main.py", "/home/caleb/repo/polliFormer/polliFormer/utils/config_utils.py",
     "config.py", "/home/caleb/repo/polliFormer/polliFormer/docs/data/copap.md"],
    "files_to_exclude": ["dataset_processor.py"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/polliFormer-deploymentXL.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer_deploymentXL_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["loss", "models", "h5data", "aug", "utils",
    "ops_schedule", "optimizers", "lr_schedulers", "tools"],
    "include_top_level_files": ["README.md", "setup.py", ".gitignore"],
    "included_extensions": [".py", ".md", ".txt", ".yaml", ".sh"],
    "files_to_include": [
    "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_reptilia_mFormerV1_sm_run7_NS1_16e.yaml",
    "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_reptilia_mFormerV1_sm_run7_NS2_16e.yaml",
    "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_reptilia_mFormerV1_sm_run7_NS5_16e.yaml",
    "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_reptilia_mFormerV1_sm_run6d3_16e.yaml",
    "/home/caleb/repo/polliFormer/tools/docker/Dockerfile",
    "/home/caleb/repo/polliFormer/polliFormer/requirements.txt",
    "/home/caleb/repo/polliFormer/work/active/assets/datasets/dataset_sizes.json"
    ],
    "additional_dirs_to_traverse": [
      "/home/caleb/repo/polliFormer/docs",
      "/home/caleb/repo/polliFormer/configs/model/archs",
      "/home/caleb/repo/polliFormer/tools",
      "/home/caleb/repo/polliFormer/dev/deployment/hyperbolic"
    ],
    "files_to_exclude": ["console_ui.py"],
    "subdirs_to_exclude": ["utils/inference"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/polliFormer-deploymentXLw.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer_deploymentXLw_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["loss", "models", "h5data", "aug", "utils",
    "ops_schedule", "optimizers", "lr_schedulers"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".md", ".txt", ".yaml", ".sh"],
    "files_to_include": [
    "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_mini_mFormerV1_sm_run2.yaml",
    "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_mini_mFormerV1_sm_run2_Phase1.yaml",
    "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_aves_mFormerV1_md_run2.yaml",
    "/home/caleb/repo/polliFormer/tools/docker/Dockerfile",
    "/home/caleb/repo/ibrida/extra/generator/configs/prod/amphibia_v0r1_full_hybrid_384.json",
    "/home/caleb/repo/ibrida/extra/generator/configs/prod/amphibia_v0r1_mini_hybrid_384.json",
    "/home/caleb/repo/ibrida/extra/generator/configs/prod/angiospermae_v0r1_full_hybrid_384.json",
    "/home/caleb/repo/ibrida/extra/generator/configs/prod/aves_v0r1_full_hybrid_384.json",
    "/home/caleb/repo/ibrida/extra/generator/configs/prod/mammalia_v0r1_full_hybrid_384.json",
    "/home/caleb/repo/ibrida/extra/generator/configs/prod/reptilia_v0r1_full_hybrid_384.json",
    "/home/caleb/repo/polliFormer/work/active/assets/dataset_sizes.json",
    "/home/caleb/repo/polliFormer/work/active/Apr15a_25/image_verification_implementation_summary.md",
    "/home/caleb/repo/polliFormer/work/active/Apr15b_25/additional_preflight.md",
    "/home/caleb/repo/polliFormer/work/active/Apr15b_25/plan2.md",
    "/home/caleb/repo/polliFormer/work/active/Apr15b_25/plan3.md",
    "/home/caleb/repo/polliFormer/work/active/Apr15b_25/plan4.md",
    "/home/caleb/repo/polliFormer/work/active/Apr15b_25/preflight_progress.md",
    "/home/caleb/repo/uv/docs/pip/index.md",
    "/home/caleb/repo/uv/docs/pip/environments.md",
    "/home/caleb/repo/uv/docs/pip/packages.md",
    "/home/caleb/repo/uv/docs/pip/compile.md",
    "/home/caleb/repo/uv/docs/pip/compatibility.md",
    "/home/caleb/repo/uv/docs/concepts/cache.md",
    "/home/caleb/repo/uv/docs/concepts/python-versions.md",
    "/home/caleb/repo/uv/docs/concepts/resolution.md",
    "/home/caleb/repo/uv/docs/concepts/projects/layout.md",
    "/home/caleb/repo/uv/docs/concepts/projects/dependencies.md",
    "/home/caleb/repo/uv/docs/configuration/authentication.md",
    "/home/caleb/repo/uv/docs/configuration/environment.md",
    "/home/caleb/repo/uv/docs/guides/install-python.md",
    "/home/caleb/repo/uv/docs/guides/projects.md",
    "/home/caleb/repo/uv/docs/guides/scripts.md",
    "/home/caleb/repo/uv/docs/guides/tools.md"
    ],
    "additional_dirs_to_traverse": [
      "/home/caleb/repo/polliFormer/docs",
      "/home/caleb/repo/polliFormer/configs/model/archs",
      "/home/caleb/repo/polliFormer/extra/mFormerV1_ckpt_inspections",
      "/home/caleb/repo/polliFormer/tools",
      "/home/caleb/repo/ibrida/src/ibrida/utils",
      "/home/caleb/repo/polliFormer/dev/deployment/hyperbolic"
    ],
    "files_to_exclude": ["console_ui.py"],
    "subdirs_to_exclude": ["utils/inference"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/polliFormer-doxDyn.json">
{
  "repo_root": "/home/caleb/repo/polliFormer",
  "export_name": "polliFormer_doxDyn_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["docs", "style_guide", "polliFormer/ops_schedule", "polliFormer/loss", "polliFormer/utils"],
  "include_top_level_files": "all",
  "included_extensions": [".py"],
  "files_to_include": ["polliFormer/main.py", "polliFormer/config.py",
    "h5data/build.py","h5data/h5dataloader.py", "h5data/h5_dataloader.py", "h5data/base_prefetching_dataset.py", "h5data/prefetching_hybrid_dataset.py",
  "utils/schedule_utils.py",
    "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_hybrid_ft_sm_15.yaml"],
  "files_to_exclude": ["console_ui.py", "backblaze.py", "hpc_utils.py", "dataset_metadata.py", "autobatch.py"],
  "subdirs_to_exclude": ["polliFormer/utils/inference"],
  "always_exclude_patterns": ["export.txt"],
  "exhaustive_dir_tree": false
}
        </file>
        <file path="configs/polliFormer-gradnorm.json">
{
  "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
  "export_name": "polliFormer_gradnorm_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["loss", "ops_schedule", "lr_schedulers"],
  "include_top_level_files": "all",
  "included_extensions": [".py", ".md"],
  "files_to_include": [
    "optimizers/build.py",
    "optimizers/multi_optimizer.py",
    "utils/param_filters.py", "utils/unified_filtering.py",
    "utils/schedule_utils.py",
    "models/mFormerV0.py",
    "/home/caleb/repo/polliFormer/style_guide/metrics.md",
    "/home/caleb/repo/polliFormer/style_guide/model_metadata.md",
    "/home/caleb/repo/polliFormer/style_guide/schedule_parameters.md",
    "/home/caleb/repo/polliFormer/docs/training/scheduling.md",
    "/home/caleb/repo/polliFormer/docs/training/metrics.md"

  ],
  "files_to_exclude": ["console_ui.py", "backblaze.py"],
  "subdirs_to_exclude": ["utils/inference"],
  "always_exclude_patterns": ["export.txt"],
  "exhaustive_dir_tree": true
}
        </file>
        <file path="configs/polliFormer-gradnorm2.json">
{
  "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
  "export_name": "polliFormer_gradnorm2_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["loss", "ops_schedule", "lr_schedulers"],
  "include_top_level_files": "all",
  "included_extensions": [".py", ".md"],
  "files_to_include": [
    "optimizers/build.py",
    "optimizers/multi_optimizer.py",
    "utils/schedule_utils.py",
    "utils/logging/wandb.py",
    "utils/metrics/tracker.py",
    "utils/metrics/metrics.py",
    "utils/metrics/step_metrics_logger.py",
    "/home/caleb/repo/polliFormer/style_guide/metrics.md",
    "/home/caleb/repo/polliFormer/style_guide/schedule_parameters.md",
    "/home/caleb/repo/polliFormer/docs/training/scheduling.md",
    "/home/caleb/repo/polliFormer/docs/training/metrics.md",
    "/home/caleb/repo/polliFormer/docs/evaluation/validation.md",
    "/home/caleb/repo/polliFormer/docs/evaluation/metrics.md"
  ],
  "files_to_exclude": ["console_ui.py", "backblaze.py"],
  "subdirs_to_exclude": ["utils/inference"],
  "always_exclude_patterns": ["export.txt"],
  "exhaustive_dir_tree": true
}
        </file>
        <file path="configs/polliFormer-gradnormSlim.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer_gradnormSlim_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["loss"],
    "include_top_level_files": "all",
    "included_extensions": [".py"],
    "files_to_include": [
        "utils/param_filters.py",
    "models/mFormerV0.py", "models/heads/utils.py",
    "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_hybrid_ft_sm_11.yaml"],
    "files_to_exclude": ["console_ui.py", "backblaze.py", "optimizer.py", "config.py"],
    "subdirs_to_exclude": ["utils/inference"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/polliFormer-gradnormSlim2.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer_gradnormSlim2_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["loss"],
    "include_top_level_files": "all",
    "included_extensions": [".py"],
    "files_to_include": [
    "models/mFormerV0.py", "models/heads/utils.py"],
    "files_to_exclude": ["console_ui.py", "backblaze.py", "optimizer.py", "config.py", "lr_scheduler.py"],
    "subdirs_to_exclude": ["utils/inference"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/polliFormer-hierarchyMini.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer_classificationMini_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["loss", "models/heads"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".md"],
    "files_to_include": [
    "models/mFormerV0.py", "models/build.py", "models/model_factory.py", "models/base_model.py",
    "/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_sm.yaml",
    "/home/caleb/repo/polliFormer/docs/advanced_topics/hierarchical_approaches.md"],
    "files_to_exclude": ["console_ui.py", "backblaze.py", "optimizer.py", "validation.py"],
    "subdirs_to_exclude": ["utils/inference"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/polliFormer-hierarchyXL.json">
{
  "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
  "export_name": "polliFormer_hierarchyXL_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["loss", "models", "h5data", "aug", "utils",
  "ops_schedule", "optimizers", "lr_schedulers", "tools"],
  "include_top_level_files": ["README.md", "setup.py", ".gitignore"],
  "included_extensions": [".py", ".md", ".txt", ".yaml", ".sh", ".out", ".err"],
  "files_to_include": [
  "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_reptilia_mFormerV1_sm_run7_NS1_16e.yaml",
  "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_reptilia_mFormerV1_sm_run7_NS2_16e.yaml",
  "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_reptilia_mFormerV1_sm_run7_NS5_16e.yaml",
  "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_reptilia_mFormerV1_sm_run6d3_16e.yaml",
  "/home/caleb/repo/polliFormer/tools/docker/Dockerfile",
  "/home/caleb/repo/polliFormer/polliFormer/requirements.txt",
  "/home/caleb/repo/polliFormer/work/active/assets/datasets/dataset_sizes.json"
  ],
  "additional_dirs_to_traverse": [
    "/home/caleb/repo/polliFormer/docs",
    "/home/caleb/repo/polliFormer/configs/model/archs",
    "/home/caleb/repo/polliFormer/work/active/May9a_25",
    "/home/caleb/repo/polliFormer/logs/metamask_debug_20250509_192736"
  ],
  "files_to_exclude": ["console_ui.py"],
  "subdirs_to_exclude": ["utils/inference"],
  "always_exclude_patterns": ["export.txt"],
  "exhaustive_dir_tree": true
}
        </file>
        <file path="configs/polliFormer-logging.json">
{
  "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
  "export_name": "polliFormer_logging_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["utils/metrics"],
  "include_top_level_files": "none",
  "included_extensions": [".py"],
  "files_to_include": ["main.py", "logger.py", "config.py", "ops_schedule.py",
  "utils/wandb.py", "utils/logging_utils.py", "utils/distributed.py"],
  "files_to_exclude": ["console_ui.py", "backblaze.py", "taxAlign.py"],
  "subdirs_to_exclude": ["utils/inference"],
  "always_exclude_patterns": ["export.txt"],
  "exhaustive_dir_tree": true
}
        </file>
        <file path="configs/polliFormer-loggingSlim.json">
{
  "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
  "export_name": "polliFormer_loggingSlim_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": [],
  "include_top_level_files": "none",
  "included_extensions": [".py"],
  "files_to_include": ["main.py", "ops_schedule.py",
  "utils/wandb.py", "utils/logging_utils.py", "utils/metrics/tracker.py"],
  "files_to_exclude": ["console_ui.py", "backblaze.py", "taxAlign.py"],
  "subdirs_to_exclude": ["utils/inference"],
  "always_exclude_patterns": ["export.txt"],
  "exhaustive_dir_tree": true
}
        </file>
        <file path="configs/polliFormer-loss.json">
{
  "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
  "export_name": "polliFormer_loss_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["loss", "models"],
  "include_top_level_files": "all",
  "included_extensions": [".py", ".md"],
  "files_to_include": [
    "utils/schedule_utils.py",
    "utils/logging/wandb.py",
    "utils/metrics/tracker.py",
    "utils/metrics/metrics.py",
    "utils/metrics/step_metrics_logger.py",
    "/home/caleb/repo/polliFormer/style_guide/metrics.md",
    "/home/caleb/repo/polliFormer/style_guide/schedule_parameters.md",
    "/home/caleb/repo/polliFormer/docs/training/scheduling.md",
    "/home/caleb/repo/polliFormer/style_guide/model_metadata.md",
    "/home/caleb/repo/polliFormer/docs/training/metrics.md",
    "/home/caleb/repo/polliFormer/docs/evaluation/validation.md",
    "/home/caleb/repo/polliFormer/docs/evaluation/metrics.md"
  ],
  "files_to_exclude": ["console_ui.py", "backblaze.py"],
  "subdirs_to_exclude": ["utils/inference"],
  "always_exclude_patterns": ["export.txt"],
  "exhaustive_dir_tree": true
}
        </file>
        <file path="configs/polliFormer-loss2.json">
{
  "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
  "export_name": "polliFormer_loss2_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["loss", "models/heads"],
  "include_top_level_files": "all",
  "included_extensions": [".py", ".md"],
  "files_to_include": [
    "models/build.py",
    "models/mFormerV0.py",
    "utils/schedule_utils.py",
    "utils/logging/wandb.py",
    "utils/metrics/tracker.py",
    "utils/metrics/metrics.py",
    "utils/metrics/step_metrics_logger.py"
  ],
  "files_to_exclude": ["console_ui.py", "backblaze.py"],
  "subdirs_to_exclude": ["utils/inference"],
  "always_exclude_patterns": ["export.txt"],
  "exhaustive_dir_tree": true
}
        </file>
        <file path="configs/polliFormer-loss3.json">
{
  "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
  "export_name": "polliFormer_loss3_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["loss", "models/heads"],
  "include_top_level_files": "all",
  "included_extensions": [".py", ".md"],
  "files_to_include": [
    "models/build.py",
    "models/mFormerV0.py",
    "h5data/vectorized_dataset_processor.py",
    "/home/caleb/repo/polliFormer/work/active/Mar17_25/1_taxonomy_label_smoothing_plan.md"
  ],
  "files_to_exclude": ["console_ui.py", "backblaze.py"],
  "subdirs_to_exclude": ["utils/inference"],
  "always_exclude_patterns": ["export.txt"],
  "exhaustive_dir_tree": true
}
        </file>
        <file path="configs/polliFormer-mFormerV1.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer-mFormerV1_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": [],
    "include_top_level_files": "none",
    "included_extensions": [".py", ".yaml"],
    "files_to_include": ["models/mFormerV0.py", "models/build.py", "models/blocks/mb_conv.py", "models/blocks/relative_mhsa.py", "models/blocks/drop_path.py",
"/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_sm.yaml",
    "/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_md.yaml", "/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_lg.yaml",
    "utils/checkpoint.py", "utils/model_utils.py",
    "/home/caleb/repo/polliFormer/dev/papers/Diao et al. - 2022 - MetaFormer A Unified Meta Framework for Fine-Grai.md",
    "/home/caleb/repo/polliFormer/dev/papers/Heo et al. - 2024 - Rotary Position Embedding for Vision Transformer.md",
    "/home/caleb/repo/polliFormer/dev/notes/model/mFormerV1/PRD.md"],
    "files_to_exclude": ["export.py", "enhanced_mb_conv.py", "console_ui.py"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/polliFormer-meta.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer_meta_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["ops_schedule", "utils/metrics", "utils/logging"],
    "files_to_include": ["h5data/build.py", "h5data/vectorized_dataset_processor.py",
        "h5data/h5dataloader.py", "h5data/base_prefetching_dataset.py", "h5data/prefetching_hybrid_dataset.py",
        "utils/meta_utils.py", "utils/schedule_utils.py", "utils/distributed.py",
        "models/mFormerV0.py",
        "/home/caleb/repo/polliFormer/style_guide/metrics.md",
        "/home/caleb/repo/polliFormer/style_guide/model_metadata.md",
        "/home/caleb/repo/polliFormer/style_guide/schedule_parameters.md"],
    "files_to_exclude": ["console_ui.py", "backblaze.py", "autobatch.py"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".yaml", ".sh"],
    "always_exclude_patterns": ["export.txt", "224.yaml", ".bak.py"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/polliFormer-metrics.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer_metrics_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["utils/metrics", "utils/logging"],
    "subdirs_to_exclude": ["polliFormer/evaluation", "polliFormer/logs", "polliFormer/serving", "polliFormer/tests", "polliFormer/utils/inference", "polliFormer/aug"],
    "include_top_level_files": "all",
    "included_extensions": [".py"],
    "files_to_include": ["utils/backblaze.py", "utils/checkpoint.py"],
    "files_to_exclude": ["console_ui.py"],
    "always_exclude_patterns": ["export.txt", ".egg-info", "__pycache__", ".DS_Store"],
    "exhaustive_dir_tree": true,
    "dump_config": true
  }
        </file>
        <file path="configs/polliFormer-models-codeOnly.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer-models-codeOnly_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["models"],
    "include_top_level_files": "none",
    "included_extensions": [".py"],
    "files_to_exclude": ["export.py", "mFormerV1.py"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/polliFormer-models.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer-models_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["models"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".yaml"],
    "files_to_include": ["/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_hybrid.yaml", "/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_sm.yaml",
    "/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_md.yaml", "/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_lg.yaml",
    "/home/caleb/repo/polliFormer/dev/notes/model/mFormerV0/reference_MetaFG_meta_implementation.xml", "/home/caleb/repo/polliFormer/dev/notes/model/mFormerV0/reference_methods.md",
    "/home/caleb/repo/polliFormer/polliFormer/utils/checkpoint.py", "/home/caleb/repo/polliFormer/polliFormer/utils/model_utils.py"],
    "files_to_exclude": ["export.py", "enhanced_mb_conv.py", "console_ui.py"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/polliFormer-modelsDyn.json">
{
  "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
  "export_name": "polliFormer_modelsDyn_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["models"],
  "include_top_level_files": "all",
  "included_extensions": [".py"],
  "files_to_include": ["/home/caleb/repo/polliFormer/polliFormer/utils/config_utils.py", "/home/caleb/repo/polliFormer/polliFormer/utils/autobatch.py",
  "/home/caleb/repo/polliFormer/polliFormer/h5data/vectorized_dataset_processor.py", "h5data/h5dataloader.py", "h5data/prefetching_hybrid_dataset.py", "aug/cpu/selective_mixup.py",
"/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_sm.yaml", "/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_md.yaml",
"/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_lg.yaml", "/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_xl.yaml"],
  "files_to_exclude": [],
  "subdirs_to_exclude": ["configs/legacy"],
  "always_exclude_patterns": ["export.txt"],
  "exhaustive_dir_tree": true
}
        </file>
        <file path="configs/polliFormer-modelsPruned-codeOnly.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer/models",
    "export_name": "polliFormer_modelsPruned_codeOnly_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["aggregation", "attention", "heads", "utils"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".yaml"],
    "files_to_exclude": ["export.py"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/polliFormer-modelsPrunedInv-codeOnly.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer/models",
    "export_name": "polliFormer_modelsPrunedInv_codeOnly_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["blocks", "components", "normalization", "resolvers"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".yaml"],
    "files_to_exclude": ["export.py"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/polliFormer-modelsSlim.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer-modelsSlim_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": [],
    "include_top_level_files": "none",
    "included_extensions": [".py", ".yaml"],
    "files_to_include": ["models/mFormerV0.py", "models/build.py", "models/blocks/mb_conv.py", "models/blocks/relative_mhsa.py", "models/blocks/drop_path.py",
"/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_sm.yaml",
    "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_hybrid_ft_sm_2.yaml",
    "/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_md.yaml", "/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_lg.yaml",
    "utils/checkpoint.py", "utils/model_utils.py",
    "/home/caleb/repo/polliFormer/dev/papers/Diao et al. - 2022 - MetaFormer A Unified Meta Framework for Fine-Grai.md",
    "/home/caleb/repo/polliFormer/dev/notes/model/mFormerV1/PRD.md"],
    "files_to_exclude": ["export.py", "enhanced_mb_conv.py", "console_ui.py"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/polliFormer-modelsSlim2.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer-modelsSlim2_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": [],
    "include_top_level_files": "none",
    "included_extensions": [".py", ".yaml"],
    "files_to_include": ["models/mFormerV0.py", "models/build.py", "models/blocks/mb_conv.py", "models/blocks/drop_path.py",
    "models/utils/initialization.py", "models/utils/conversion.py",
        "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_hybrid_ft_sm.yaml", "/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_sm.yaml",
        "/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_md.yaml", "/home/caleb/repo/polliFormer/configs/model/archs/mFormerV0/mFormerV0_lg.yaml",
    "utils/checkpoint.py", "utils/model_utils.py"],
    "files_to_exclude": ["export.py", "enhanced_mb_conv.py", "console_ui.py"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/polliFormer-paramFilters.json">
{
  "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
  "export_name": "polliFormer_paramFilters_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["loss","components", "utils/logging"],
  "include_top_level_files": "all",
  "included_extensions": [".py"],
  "files_to_include": [ "/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_hybrid_ft_sm_14.yaml", 
"utils/param_filters.py", "utils/distributed.py", "utils/checkpoint.py", "utils/model_utils.py",
"models/mFormerV0.py", "models/build.py", "models/blocks/mb_conv.py", "models/blocks/relative_mhsa.py", "models/blocks/drop_path.py",
  "/home/caleb/repo/polliFormer/style_guide/metrics.md"],
  "files_to_exclude": ["console_ui.py", "backblaze.py"],
  "subdirs_to_exclude": ["utils/inference"],
  "always_exclude_patterns": ["export.txt"],
  "exhaustive_dir_tree": true
}
        </file>
        <file path="configs/polliFormer-serve.json">
{
    "repo_root": "/home/caleb/repo/Polli-Brain/metaformer/torchserve/polliFormer0",
    "export_name": "polliFormer_serve_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["."],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".yaml", ".properties", ".sh", ".xml", ".txt"],
    "subdirs_to_exclude": ["pkgs", "test"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/polliFormer-tests.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer_tests_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["aug", "h5data", "models", "loss", "utils", "components", "ibrida", "evaluation", "serving", "tests"],
    "include_top_level_files": "all",
    "included_extensions": [".py"],
    "files_to_include": ["copap.md", "inheritance.md", "model.md", "training.md"],
    "files_to_exclude": ["main_v0.py", "main_v1.py", "completed_plans.md"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/polliFormer-train.json">
{
  "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
  "export_name": "polliFormer_train_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["loss"],
  "include_top_level_files": "all",
  "included_extensions": [".py"],
  "files_to_include": ["/home/caleb/repo/polliFormer/configs/experiments/tests/blade_amphibia_hybrid_ft_sm_9.yaml",
  "h5data/build.py", "h5data/base_prefetching_dataset.py", "h5data/prefetching_hybrid_dataset.py", "h5data/h5dataloader.py", "h5data/prefetching_h5_dataset.py", "h5data/h5dataloader.py",
  "aug/cpu/selective_mixup.py", "aug/gpu/selective_mixup.py",
  "models/mFormerV0.py"],
  "files_to_exclude": ["console_ui.py", "dataset_metadata.py", "config_utils.py"],
  "subdirs_to_exclude": ["configs/legacy", "utils/inference"],
  "always_exclude_patterns": ["export.txt"],
  "exhaustive_dir_tree": true
}
        </file>
        <file path="configs/polliFormer-utils.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer-utils_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["utils"],
    "include_top_level_files": "none",
    "included_extensions": [".py", ".yaml"],
    "files_to_exclude": ["export.py"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/polliFormer.json">
{
    "repo_root": "/home/caleb/repo/polliFormer/polliFormer",
    "export_name": "polliFormer_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["aug", "evaluation", "h5data", "ibrida", "loss", "lr_schedulers", "models", "ops_schedule", "utils",
        "serving", "tests", "tools"
    ],
    "include_top_level_files": "none",
    "included_extensions": [".py"],
    "files_to_exclude": ["README.md", "TODO.md", "mFormerV1.py", "mFormerV1.md", "training.md", "mFormerV1.py", "export.py"],
    "always_exclude_patterns": ["export.txt", ".egg-info", "__pycache__", ".DS_Store"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/polliOS-codeOnly.json">
{
    "repo_root": "/home/caleb/repo/polliOS-core/PolliOS",
    "export_name": "polliOS-core-codeOnly-export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["backend", "brain", "engine", "logger", "polliCLI", "runner", "swarm", "updaters", "utils"],
    "include_top_level_files": "none",
    "included_extensions": [".py"],
    "exhaustive_dir_tree": false,
    "subdirs_to_exclude": ["updaters", "utils", ".git"],
    "depth": 10
  }
  
  
        </file>
        <file path="configs/polliOS.json">
{
    "repo_root": "/home/caleb/repo/polliOS-core/PolliOS",
    "export_name": "polliOS-core-repo-export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["PolliOS"],
    "include_top_level_files": "none",
    "included_extensions": [".py", ".yml", ".md"],
    "exhaustive_dir_tree": false,
    "subdirs_to_exclude": ["updaters", "utils"],
    "depth": 10
  }
  
  
        </file>
        <file path="configs/pollinalysis-code-mini.json">
{
    "repo_root": "/Users/carbon/repo/pollinalysis",
    "export_name": "pollinalysis_code_mini_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["src/pollinalysis/masking", "src/pollinalysis/io"],
    "files_to_include": ["/Users/carbon/repo/pollinalysis/configs/insecta_only_deepsort_8.json",
    "/Users/carbon/repo/pollinalysis/src/pollinalysis/cli.py",
    "/Users/carbon/repo/pollinalysis/src/pollinalysis/config.py"],
    "files_to_exclude": ["CONTRIBUTING.md", "LICENSE", "LICENSE_cctorch", "CODE_OF_CONDUCT.md", "README.md",
    "prompt.md",
    "temp_analyze_masks.py",
    "CLAUDE.md",
    "TODO.md"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".md", ".ipynb", ".toml"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/pollinalysis-code.json">
{
    "repo_root": "/Users/carbon/repo/pollinalysis",
    "export_name": "pollinalysis_code_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["src", "app", "docs"],
    "files_to_include": ["/Users/carbon/repo/pollinalysis/configs/runs/default_with_merge.yaml",
    "/Users/carbon/repo/pollinalysis/configs/prompts/gemini_prompts.jsonl",
    "/Users/carbon/repo/pollinalysis/configs/metadata/DiNat17_classes.yaml",
    "/Users/carbon/repo/pollinalysis/configs/README.md"],
    "files_to_exclude": ["CONTRIBUTING.md", "LICENSE", "LICENSE_cctorch", "CODE_OF_CONDUCT.md", "README.md",
    "prompt.md", "debug_gemini_padding.py"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".md", ".ipynb", ".toml"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/pollinalysis-full.json">
{
    "repo_root": "/Users/carbon/repo/pollinalysis",
    "export_name": "pollinalysis_full_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["src", "app", "configs", "docs"],
    "files_to_include": ["/Users/carbon/repo/pollinalysis/work/active/context/initial_spec.md",
      "/Users/carbon/repo/pollinalysis/work/active/context/appendix.md",
      "/Users/carbon/repo/pollinalysis/work/active/May6_25/grid_search.md",
      "/Users/carbon/repo/pollinalysis/work/misc/simon-willimson-gemini-image-seg.md",
    "/Users/carbon/repo/pollinalysis-tools/misc/Spatial_understanding.ipynb"],
    "files_to_exclude": ["CONTRIBUTING.md", "LICENSE", "LICENSE_cctorch", "CODE_OF_CONDUCT.md",
    "prompt.md"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".md", ".ipynb", ".toml", ".yaml", ".log", ".txt", ".json", ".path"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false,
    "additional_dirs_to_traverse": [
        "/home/caleb/repo/sam2/notebooks",
        "/home/caleb/repo/sam2/sam2",
        "/home/caleb/repo/sam2/tools",
        "/Users/carbon/repo/pollinalysis-tools/preprocessing/squarecrop/squarecrop",
        "/home/caleb/repo/trackers/trackers"
      ]
}
        </file>
        <file path="configs/pollinalysis.json">
{
    "repo_root": "/Users/carbon/repo/pollinalysis",
    "export_name": "pollinalysis_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["src", "configs"],
    "files_to_include": [],
    "files_to_exclude": ["CONTRIBUTING.md", "LICENSE", "LICENSE_cctorch", "CODE_OF_CONDUCT.md", "README.md",
    "prompt.md"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".md", ".yaml", ".toml"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/rope-vit.json">
{
  "repo_root": "/home/caleb/repo/rope-vit/",
  "export_name": "rope-vit_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["models", "self-attn"],
  "include_top_level_files": "all",
  "included_extensions": [".py", ".md", ".txt"],
  "subdirs_to_exclude": ["__pycache__", ".git", ".venv", ".vscode"],
  "files_to_exclude": [],
  "always_exclude_patterns": ["*.pyc", "*.pyo", "*.pyd", "*.so", "*.dylib", "*.dll", "*.log", "*.swp", "*.swo", "*.DS_Store"],
  "depth": -1,
  "exhaustive_dir_tree": true,
  "dump_config": false
}

        </file>
        <file path="configs/sam2-webapp.json">
{
    "repo_root": "/home/caleb/repo/sam2/",
    "export_name": "sam2-webapp_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["notebooks", "sam2", "tools", "demo"],
    "files_to_include": [],
    "files_to_exclude": ["CONTRIBUTING.md", "LICENSE", "LICENSE_cctorch", "CODE_OF_CONDUCT.md"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".md", ".ipynb", ".Dockerfile", ".yaml", ".yml", ".html", ".graphql", ".ts", ".tsx", ".json", ".css", ".js", ".yaml", ".yml", ".graphql", ".dockerignore"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/sam2.json">
{
    "repo_root": "/home/caleb/repo/sam2/",
    "export_name": "sam2_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["notebooks", "sam2", "tools"],
    "files_to_include": [],
    "files_to_exclude": ["CONTRIBUTING.md", "LICENSE", "LICENSE_cctorch", "CODE_OF_CONDUCT.md"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".md", ".ipynb", ".Dockerfile", ".yaml", ".toml", ".yml", ".html", ".graphql", ".ts", ".tsx", ".json", ".css", ".js", ".yaml", ".yml", ".graphql", ".dockerignore"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/sam2_demo.json">
{
    "repo_root": "/home/caleb/repo/sam2/demo",
    "export_name": "sam2_demo_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["frontend"],
    "subdirs_to_exclude": ["frontend/node_modules", "frontend/dist", "frontend/public", "frontend/src/assets", "frontend/src/components/ui/icons", "frontend/src/components/ui/icons/icons",
    "frontend/src/common/components/gallery", "frontend/src/common/codecs", "frontend/src/common/tracker", "__generated__"],
    "files_to_include": ["/home/caleb/repo/sam2/docker-compose.yaml", "/home/caleb/repo/sam2/backend.Dockerfile", "/home/caleb/repo/sam2/demo/frontend/frontend.Dockerfile",
    "/home/caleb/repo/sam2/demo/backend/server/app_conf.py", "/home/caleb/repo/sam2/demo/backend/server/app.py"],
    "files_to_exclude": [],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".md", ".ts", ".tsx", ".json", ".html", ".css", ".js", ".yaml", ".yml", ".graphql", ".dockerignore"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/squarecrop.json">
{
    "repo_root": "/Users/carbon/repo/pollinalysis-tools/preprocessing/squarecrop",
    "export_name": "squarecrop_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["configs", "logs"],
    "files_to_include": [],
    "files_to_exclude": ["CONTRIBUTING.md", "LICENSE", "LICENSE_cctorch", "CODE_OF_CONDUCT.md",
    "prompt.md"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".json", ".md", ".log"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/trackers.json">
{
    "repo_root": "/home/caleb/repo/trackers",
    "export_name": "trackers_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["docs", "trackers"],
    "files_to_include": ["pyproject.toml", "README.md"],
    "files_to_exclude": ["CONTRIBUTING.md", "LICENSE", "LICENSE_cctorch", "CODE_OF_CONDUCT.md"],
    "include_top_level_files": "none",
    "included_extensions": [".py", ".md", ".ipynb", ".toml"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }
        </file>
        <file path="configs/uv_docs_raw.json">
{
    "repo_root": "/home/caleb/repo/uv",
    "export_name": "uv_docs_raw_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["docs"],
    "include_top_level_files": "none",
    "files_to_include": [
    "/home/caleb/repo/uv/README.md",
    "/home/caleb/repo/uv/STYLE.md"
    ],
    "included_extensions": [".md"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": true
  }
        </file>
        <file path="configs/uv_med.json">
{
  "repo_root": "/home/caleb/repo/uv",
  "output_dir": "/home/caleb/repo/utils/export_repo/context",
  "export_name": "uv_med_export.xml",
  "include_top_level_files": ["README.md"],
  "dirs_to_traverse": [
    "docs/getting-started",
    "docs/concepts",
    "docs/configuration",
    "docs/guides",
    "docs/pip",
    "docs/reference/policies",
    "docs/reference/troubleshooting"
  ],
  "files_to_include": [
    "docs/reference/settings.md"
  ],
  "dirs_for_tree": [
    "docs"
  ],
  "included_extensions": [".md"],
  "subdirs_to_exclude": [
    "docs/concepts/projects",
    "docs/guides/integration"
  ],
  "files_to_exclude": [
    "docs/index.md",
    "docs/getting-started/index.md",
    "docs/concepts/index.md",
    "docs/concepts/projects/index.md",
    "docs/configuration/index.md",
    "docs/guides/index.md",
    "docs/guides/integration/index.md",
    "docs/pip/index.md",
    "docs/reference/index.md",
    "docs/reference/policies/index.md",
    "docs/reference/troubleshooting/index.md",
    "docs/reference/resolver-internals.md",
    "docs/reference/benchmarks.md",
    "docs/reference/cli.md"
  ],
  "always_exclude_patterns": ["export.xml", "uv_mini_export.xml", "uv_med_export.xml", "uv_xl_export.xml"],
  "depth": -1,
  "exhaustive_dir_tree": false,
  "dump_config": false
} 
        </file>
        <file path="configs/uv_mini.json">
{
  "repo_root": "/home/caleb/repo/uv",
  "output_dir": "/home/caleb/repo/utils/export_repo/context",
  "export_name": "uv_mini_export.xml",
  "include_top_level_files": ["README.md"],
  "dirs_to_traverse": [
    "docs/getting-started",
    "docs/pip",
    "docs/concepts",
    "docs/concepts/projects",
    "docs/configuration",
    "docs/guides"
  ],
  "files_to_include": [
    "docs/getting-started/installation.md",
    "docs/getting-started/first-steps.md",
    "docs/getting-started/features.md",
    "docs/getting-started/help.md",
    "docs/pip/index.md",
    "docs/pip/environments.md",
    "docs/pip/packages.md",
    "docs/pip/compile.md",
    "docs/pip/compatibility.md",
    "docs/concepts/cache.md",
    "docs/concepts/python-versions.md",
    "docs/concepts/resolution.md",
    "docs/concepts/projects/layout.md",
    "docs/concepts/projects/dependencies.md",
    "docs/configuration/authentication.md",
    "docs/configuration/environment.md",
    "docs/guides/install-python.md",
    "docs/guides/projects.md",
    "docs/guides/scripts.md",
    "docs/guides/tools.md"
  ],
  "dirs_for_tree": [
    "docs/getting-started",
    "docs/pip",
    "docs/concepts",
    "docs/configuration",
    "docs/guides"
  ],
  "included_extensions": [".md"],
  "subdirs_to_exclude": [],
  "files_to_exclude": [
    "docs/pip/inspection.md",
    "docs/pip/dependencies.md",
    "docs/concepts/index.md",
    "docs/concepts/projects/index.md",
    "docs/concepts/projects/init.md",
    "docs/concepts/projects/run.md",
    "docs/concepts/projects/sync.md",
    "docs/concepts/projects/config.md",
    "docs/concepts/projects/build.md",
    "docs/concepts/projects/workspaces.md",
    "docs/concepts/tools.md",
    "docs/configuration/index.md",
    "docs/configuration/files.md",
    "docs/configuration/indexes.md",
    "docs/configuration/installer.md",
    "docs/guides/index.md",
    "docs/guides/package.md",
    "docs/guides/integration"
  ],
  "always_exclude_patterns": ["export.xml", "uv_mini_export.xml", "uv_med_export.xml", "uv_xl_export.xml"],
  "depth": -1,
  "exhaustive_dir_tree": false,
  "dump_config": false
} 
        </file>
        <file path="configs/uv_xl.json">
{
  "repo_root": "/home/caleb/repo/uv",
  "output_dir": "/home/caleb/repo/utils/export_repo/context",
  "export_name": "uv_xl_export.xml",
  "include_top_level_files": ["README.md"],
  "dirs_to_traverse": [
    "docs"
  ],
  "files_to_include": [],
  "dirs_for_tree": ["docs"],
  "included_extensions": [".md"],
  "subdirs_to_exclude": [],
  "files_to_exclude": [
    "STYLE.md",
    "docs/index.md",
    "docs/getting-started/index.md",
    "docs/concepts/index.md",
    "docs/concepts/projects/index.md",
    "docs/configuration/index.md",
    "docs/guides/index.md",
    "docs/guides/integration/index.md",
    "docs/pip/index.md",
    "docs/reference/index.md",
    "docs/reference/policies/index.md",
    "docs/reference/troubleshooting/index.md",
    "docs/reference/resolver-internals.md",
    "docs/reference/benchmarks.md"
  ],
  "always_exclude_patterns": ["export.xml", "uv_mini_export.xml", "uv_med_export.xml", "uv_xl_export.xml"],
  "depth": -1,
  "exhaustive_dir_tree": true,
  "dump_config": false
} 
        </file>
        <file path="configs/vggt.json">
{
  "repo_root": "/Users/carbon/repo/vggt",
  "export_name": "vggt_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["."],
  "include_top_level_files": "all",
  "included_extensions": [".py", ".md", ".txt"],
  "subdirs_to_exclude": ["__pycache__", ".git", ".venv", ".vscode"],
  "files_to_exclude": [],
  "always_exclude_patterns": ["*.pyc", "*.pyo", "*.pyd", "*.so", "*.dylib", "*.dll", "*.log", "*.swp", "*.swo", "*.DS_Store"],
  "depth": -1,
  "exhaustive_dir_tree": true,
  "dump_config": false
}

        </file>
        <file path="configs/wandb_sweep.json">
{
  "repo_root": "/home/caleb/repo/wandb_docs/content/guides/models/sweeps",
  "export_name": "wandb_sweep_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["define-sweep-configuration"],
  "include_top_level_files": "all",
  "included_extensions": [".md"],
  "files_to_exclude": ["logger.py"],
  "subdirs_to_exclude": ["configs/legacy"],
  "always_exclude_patterns": ["export.txt"],
  "exhaustive_dir_tree": true
}
        </file>
      </dir>
    </dir>
  </files>
</codebase_context>