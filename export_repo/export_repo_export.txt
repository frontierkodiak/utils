Export Configuration:
{
  "repo_root": "/home/caleb/repo/utils/export_repo",
  "export_name": "export_repo_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": [
    "configs"
  ],
  "include_top_level_files": "all",
  "included_extensions": [
    ".py",
    ".json"
  ],
  "subdirs_to_exclude": [],
  "files_to_exclude": [
    "export_repo_export.txt"
  ],
  "depth": -1,
  "exhaustive_dir_tree": false,
  "blacklisted_dirs": [
    "__pycache__"
  ],
  "blacklisted_files": [],
  "files_to_include": [],
  "output_file": "/home/caleb/repo/utils/export_repo/export_repo_export.txt",
  "always_exclude_patterns": [
    "export.txt"
  ],
  "exported_files_count": {},
  "total_lines": 0
}
Directory tree, stemming from root "/home/caleb/repo/utils/export_repo":
├── configs
│   ├── autocrop.json
│   ├── bulk_dl.json
│   ├── export_repo.json
│   ├── hFormer-serve.json
│   ├── metaformer.json
│   ├── metaformer1.json
│   ├── metaformer2.json
│   ├── model-explorer.json
│   ├── nextjs.json
│   ├── polliOS.json
│   └── sam2.json
├── export_repo_export.txt
├── export_repo_to_txt.py
├── ipynb_to_md.py
└── readme.md

----
Full Path: export_repo_to_txt.py

import os
import json
import sys

class RepoExporter:
    def __init__(self, config):
        self.repo_root = config['repo_root']
        self.export_name = config['export_name']
        self.delimiter = config['delimiter']
        self.dirs_to_traverse = config['dirs_to_traverse']
        self.include_top_level_files = config['include_top_level_files']
        self.included_extensions = config['included_extensions']
        self.subdirs_to_exclude = config.get('subdirs_to_exclude', [])
        self.files_to_exclude = config.get('files_to_exclude', [])
        self.depth = config.get('depth', -1)  # Default to -1 for full traversal
        self.exhaustive_dir_tree = config.get('exhaustive_dir_tree', False)
        self.blacklisted_dirs = ['__pycache__']  # Blacklist of subdirs to always omit
        self.blacklisted_files = []  # Blacklist of files to always omit
        self.files_to_include = config.get('files_to_include', [])  # Additional files to include explicitly
        self.output_file = self.get_output_file_path()
        self.files_to_exclude.append(os.path.basename(self.output_file))  # Add output file to exclude list
        self.always_exclude_patterns = config.get('always_exclude_patterns', ['export.txt'])
        self.exported_files_count = {}
        self.total_lines = 0

    def get_output_file_path(self):
        if os.path.isabs(self.export_name):
            return self.export_name
        else:
            return os.path.join(self.repo_root, self.export_name)

    def write_to_file(self, content, file_path=None, mode='a'):
        with open(self.output_file, mode, encoding='utf-8') as f:
            if file_path:
                extension = os.path.splitext(file_path)[1]
                self.exported_files_count[extension] = self.exported_files_count.get(extension, 0) + 1
                lines = content.count('\n') + 1  # Counting lines in the content
                self.total_lines += lines
                f.write(f"{self.delimiter}\nFull Path: {file_path}\n\n{content}\n\n")
            else:
                f.write(f"{content}\n")

    def should_exclude_file(self, file_path):
        relative_path = os.path.relpath(file_path, self.repo_root)
        filename = os.path.basename(file_path)
        return (any(relative_path.endswith(exclude) for exclude in self.files_to_exclude) or
                any(filename.endswith(pattern) for pattern in self.always_exclude_patterns))

    def should_exclude_dir(self, dir_path):
        relative_path = os.path.relpath(dir_path, self.repo_root)
        return any(relative_path.startswith(exclude.rstrip('*')) for exclude in self.subdirs_to_exclude)

    def traverse_directory(self, directory):
        # Ensure the directory path is absolute
        abs_directory = os.path.join(self.repo_root, directory)

        if not os.path.exists(abs_directory):
            print(f"Warning: Directory {abs_directory} does not exist. Skipping.")
            return

        for root, dirs, files in os.walk(abs_directory):
            dirs[:] = [d for d in dirs if not self.should_exclude_dir(os.path.join(root, d))]

            for file in files:
                file_path = os.path.join(root, file)
                if self.should_exclude_file(file_path):
                    continue
                file_extension = os.path.splitext(file)[1]
                if self.included_extensions == 'all' or file_extension in self.included_extensions:
                    relative_path = os.path.relpath(file_path, self.repo_root)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        self.write_to_file(content, relative_path)
                    except Exception as e:
                        print(f"Error reading file {file_path}: {str(e)}")

    def include_specific_files(self, root_dir):
        for root, dirs, files in os.walk(root_dir):
            for file in files:
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, root_dir)
                if any(relative_path.endswith(include_file) for include_file in self.files_to_include):
                    if not self.should_exclude_file(file_path):
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        self.write_to_file(content, relative_path)

    def get_directory_tree(self, directory, prefix='', current_depth=0):
        """
        Generate a string representation of the directory tree.
        """
        if self.depth != -1 and current_depth > self.depth:
            return f"{prefix}│   └── (omitted)\n"

        tree_str = ''
        items = sorted(os.listdir(directory))
        for i, item in enumerate(items):
            path = os.path.join(directory, item)
            connector = '├── ' if i < len(items) - 1 else '└── '
            if os.path.isdir(path) and item in self.blacklisted_dirs:
                tree_str += f"{prefix}{connector}{item}\n"
                tree_str += f"{prefix}│   └── (omitted)\n"
            else:
                tree_str += f"{prefix}{connector}{item}\n"
                if os.path.isdir(path):
                    extension = '' if i < len(items) - 1 else '    '
                    tree_str += self.get_directory_tree(path, prefix + extension + '│   ', current_depth + 1)
        return tree_str

    def export_repo(self):
        # Clear the output file before starting
        with open(self.output_file, 'w', encoding='utf-8') as f:
            pass

        # Write the export configuration to the output file, starting fresh
        self.write_to_file(f"Export Configuration:\n{json.dumps(vars(self), indent=2)}", mode='w')

        # Generate and write the directory tree structure starting from the repo_root
        tree_structure = f"Directory tree, stemming from root \"{self.repo_root}\":\n"
        tree_structure += self.get_directory_tree(self.repo_root, current_depth=0)
        self.write_to_file(tree_structure)

        # Handle top-level files
        if self.include_top_level_files == 'all':
            for item in os.listdir(self.repo_root):
                if item in self.files_to_exclude:  # Skip files in files_to_exclude
                    continue
                item_path = os.path.join(self.repo_root, item)
                if os.path.isfile(item_path):
                    item_extension = os.path.splitext(item)[1]
                    if self.included_extensions == 'all' or item_extension in self.included_extensions:
                        with open(item_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        self.write_to_file(content, os.path.relpath(item_path, self.repo_root))
        elif isinstance(self.include_top_level_files, list):
            for file_name in self.include_top_level_files:
                if file_name in self.files_to_exclude:  # Skip files in files_to_exclude
                    continue
                file_path = os.path.join(self.repo_root, file_name)
                if os.path.exists(file_path):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    self.write_to_file(content, file_name)

        # Start traversal from each specified directory in dirs_to_traverse
        for dir in self.dirs_to_traverse:
            self.traverse_directory(dir)

        # Include specific files by traversing from the root directory
        self.include_specific_files(self.repo_root)

        # At the end of the script, after all processing
        print(f"Exported to: {self.output_file}")
        print(f"Total number of lines: {self.total_lines}")
        print("Number of exported files by extension:")
        for ext, count in self.exported_files_count.items():
            print(f"{ext}: {count}")

def load_config(config_filename):
    """
    Load configuration from a JSON file located in the specified configs directory.
    """
    config_path = os.path.join('/home/caleb/repo/utils/export_repo/configs', config_filename)
    with open(config_path, 'r', encoding='utf-8') as config_file:
        return json.load(config_file)

def get_default_config(repo_root):
    """
    Return a default configuration when no config file is provided.
    """
    return {
        'repo_root': repo_root,
        'export_name': f"{os.path.basename(repo_root)}_export.txt",
        'delimiter': '---',
        'dirs_to_traverse': ['.'],
        'include_top_level_files': 'all',
        'included_extensions': 'all',
        'subdirs_to_exclude': ['__pycache__'],
        'files_to_exclude': [],
        'depth': 10,
        'exhaustive_dir_tree': False,
        'files_to_include': [],
        'always_exclude_patterns': ['export.txt']
    }

def main():
    if len(sys.argv) < 2:
        print("Usage: python script.py <config_filename> or <repo_root>")
        sys.exit(1)

    arg = sys.argv[1]
    if arg.endswith('.json'):
        config = load_config(arg)
    else:
        repo_root = arg
        config = get_default_config(repo_root)

    exporter = RepoExporter(config)
    exporter.export_repo()

if __name__ == "__main__":
    main()


----
Full Path: ipynb_to_md.py

import json

def convert_ipynb_to_md(ipynb_path, md_path):
    with open(ipynb_path, 'r', encoding='utf-8') as f:
        notebook = json.load(f)
    
    md_content = ""
    
    for cell in notebook['cells']:
        if cell['cell_type'] == 'markdown':
            md_content += ''.join(cell['source']) + "\n\n"
        elif cell['cell_type'] == 'code':
            md_content += "```python\n"
            md_content += ''.join(cell['source']) + "\n"
            md_content += "```\n\n"
    
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(md_content)

# Path to the Jupyter notebook
ipynb_path = 'notebooks/image_predictor_example.ipynb'
# Path to the output Markdown file
md_path = 'notebooks/image_predictor_example.md'

# Convert the notebook to Markdown
convert_ipynb_to_md(ipynb_path, md_path)


----
Full Path: configs/metaformer1.json

{
  "repo_root": "/home/caleb/repo/Polli-Brain/metaformer",
  "export_name": "metaformer_repo_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["models"],
  "include_top_level_files": "all",
  "included_extensions": [".py", ".yaml", ".md"],
  "exhaustive_dir_tree": false,
  "files_to_include": ["experiment_log.md", "base2.yaml"]
}



----
...excluded several configs...

----
Full Path: configs/sam2.json

{
    "repo_root": "/home/caleb/repo/ibrida/segment-anything-2",
    "export_name": "sam2_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["notebooks", "configs", "models"],
    "files_to_include": ["build_sam.py", "sam2_image_predictor.py", "sam2_video_predictor.py"],
    "include_top_level_files": "README.md",
    "included_extensions": [".py", ".yaml", ".md", ".ipynb"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }

----
Full Path: configs/metaformer.json

{
  "repo_root": "/home/caleb/repo/Polli-Brain/metaformer",
  "export_name": "metaformer_repo_export.txt",
  "delimiter": "----",
  "dirs_to_traverse": ["models"],
  "include_top_level_files": "all",
  "included_extensions": [".py", ".yaml", ".md"],
  "exhaustive_dir_tree": false
}



----
Full Path: configs/autocrop.json

{
    "repo_root": "/home/caleb/repo/ibrida/ibrida/s3/postprocess/autocrop",
    "export_name": "autocrop_export.txt",
    "delimiter": "----",
    "dirs_to_traverse": ["utils", "configs", "models"],
    "include_top_level_files": "all",
    "included_extensions": [".py", ".yaml"],
    "always_exclude_patterns": ["export.txt"],
    "exhaustive_dir_tree": false
  }

